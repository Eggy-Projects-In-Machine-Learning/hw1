{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PREPROCESSING HELPER FUNCTION\n",
    "\n",
    "formats image files and converts into numpy arrays of the same shape, then saves to specified location\n",
    "\n",
    "Returns 0 upon success, otherwise returns 1 (unsuccessful may be due to undesirable properties such as\n",
    "large aspect ratio)\n",
    "\"\"\"\n",
    "\n",
    "def process_file(file_path, processed_file_path, target_size = 32, aspect_ratio_thres = 1.3):\n",
    "    with Image.open(file_path) as image:\n",
    "        # crop out the longer dimension so it's square\n",
    "        width, height = image.size\n",
    "        new_size = min(width, height)\n",
    "        if new_size * aspect_ratio_thres < max(width, height):\n",
    "            # print(f'skipped due to aspect ratio too high')\n",
    "            return 1\n",
    "        left = (width - new_size) / 2\n",
    "        top = (height - new_size) / 2\n",
    "        right = (width + new_size) / 2\n",
    "        bottom = (height + new_size) / 2\n",
    "        image = image.crop((left, top, right, bottom))\n",
    "        \n",
    "        # resize\n",
    "        image = image.resize((target_size, target_size))\n",
    "\n",
    "        # convert the image to RGB\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        # convert to numpy array\n",
    "        img_array = np.array(image)\n",
    "\n",
    "        # print(f'processed array shape: {img_array.shape}')\n",
    "        if img_array.shape != (target_size, target_size, 3):\n",
    "            print(f'error! wrong shape {img_array.shape}')\n",
    "        \n",
    "        # save to file\n",
    "        np.save(processed_file_path, img_array)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MAIN PIPELINE 1\n",
    "\n",
    "preprocesses data by reading from directory and saves processed data into another directory with same structure.\n",
    "\"\"\"\n",
    "\n",
    "def preprocess(raw_data_dir, processed_data_dir):\n",
    "    # Create the processed_data directory if it doesn't exist\n",
    "    if not os.path.exists(processed_data_dir):\n",
    "        os.makedirs(processed_data_dir)\n",
    "\n",
    "    # List all subfolders in raw_data\n",
    "    for subdir in os.listdir(raw_data_dir):\n",
    "        print(f'reading directory {subdir}')\n",
    "        raw_subdir_path = os.path.join(raw_data_dir, subdir)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if not os.path.isdir(raw_subdir_path):\n",
    "            continue\n",
    "        processed_subdir_path = os.path.join(processed_data_dir, subdir)\n",
    "        \n",
    "        # Create the subfolder in processed_data if it doesn't exist\n",
    "        if not os.path.exists(processed_subdir_path):\n",
    "            os.makedirs(processed_subdir_path)\n",
    "        \n",
    "        count = 0\n",
    "        processed_count = 0\n",
    "        total = len(os.listdir(raw_subdir_path))\n",
    "        # Process each file in the subdirectory\n",
    "        for filename in os.listdir(raw_subdir_path):\n",
    "            file_path = os.path.join(raw_subdir_path, filename)\n",
    "            processed_file_path = os.path.join(processed_subdir_path, filename)\n",
    "            \n",
    "            # Process the file\n",
    "            return_code = process_file(file_path, processed_file_path)\n",
    "            count += 1\n",
    "            if return_code == 0:\n",
    "                processed_count += 1\n",
    "            if count % 100 == 0 or count == total:\n",
    "                print(f'traversed {count} / {total}, processed {processed_count}')\n",
    "                \n",
    "    print('finished preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMPORTS PROCESSED IMAGES INTO X AND Y\n",
    "\"\"\"\n",
    "\n",
    "def import_images(processed_data_dir, folders):\n",
    "    total_items = 0\n",
    "    total_categories = 0\n",
    "    image_dim = None\n",
    "\n",
    "    # List all subfolders\n",
    "    for subdir in os.listdir(processed_data_dir):\n",
    "        if folders is not None and subdir not in folders:\n",
    "            continue\n",
    "\n",
    "        subdir_path = os.path.join(processed_data_dir, subdir)\n",
    "        # Check if it's a directory\n",
    "        if not os.path.isdir(subdir_path):\n",
    "            continue\n",
    "\n",
    "        total_categories += 1\n",
    "        if total_items == 0:\n",
    "            for filename in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, filename)\n",
    "                data = np.load(file_path)\n",
    "                print(f'data shape: {data.shape}')\n",
    "                image_dim = data.shape\n",
    "                break\n",
    "        total_items += len(os.listdir(subdir_path))\n",
    "\n",
    "    print(f'found {total_items} items!')\n",
    "        \n",
    "    X = np.zeros((total_items, *image_dim))\n",
    "    print(f'x dim: {X.shape}')\n",
    "    Y = np.zeros((total_items, total_categories))\n",
    "    \n",
    "    category_counter = 0\n",
    "    item_counter = 0\n",
    "\n",
    "    # List all subfolders\n",
    "    for subdir in os.listdir(processed_data_dir):\n",
    "        if folders is not None and subdir not in folders:\n",
    "            continue\n",
    "        \n",
    "        subdir_path = os.path.join(processed_data_dir, subdir)\n",
    "        print(f'reading directory {subdir} with {len(os.listdir(subdir_path))} items')\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if not os.path.isdir(subdir_path):\n",
    "            continue\n",
    "        \n",
    "        # Process each file in the subdirectory\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            file_path = os.path.join(subdir_path, filename)\n",
    "            data = np.load(file_path)\n",
    "            \n",
    "            X[item_counter] = data\n",
    "            Y[item_counter][category_counter] = 1\n",
    "            item_counter += 1\n",
    "\n",
    "            if item_counter % 100 == 0:\n",
    "                print(f'processed {item_counter}/{len(os.listdir(subdir_path))}')\n",
    "\n",
    "        category_counter += 1\n",
    "\n",
    "    print(f'label statistics: {np.sum(Y, axis=0)}')\n",
    "    print('finished feature import')\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.num_classes = num_classes        \n",
    "\n",
    "        self.fc_layer_size = 1000\n",
    "\n",
    "        self.layer1_filters = 32\n",
    "\n",
    "        self.layer1_kernel_size = (4,4)\n",
    "        self.layer1_stride = 1\n",
    "        self.layer1_padding = 0\n",
    "\n",
    "        self.layer2_filters = 64\n",
    "\n",
    "        self.layer2_kernel_size = (2,2)\n",
    "        self.layer2_stride = 1\n",
    "        self.layer2_padding = 0\n",
    "\n",
    "        self.layer1_dim_h = (self.in_dim[1] - self.layer1_kernel_size[0]) / self.layer1_stride + 1\n",
    "        self.layer1_dim_w = (self.in_dim[2] - self.layer1_kernel_size[1]) / self.layer1_stride + 1        \n",
    "\n",
    "        self.layer2_dim_h = ((self.layer1_dim_h // 2) - self.layer2_kernel_size[0]) / self.layer2_stride + 1\n",
    "        self.layer2_dim_w = ((self.layer1_dim_w // 2)  - self.layer2_kernel_size[1]) / self.layer2_stride + 1        \n",
    "\n",
    "        print(f'layer2_dim_h {self.layer2_dim_h}\\nlayer2_dim_w {self.layer2_dim_w}')\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.layer1_filters, self.layer1_kernel_size, stride=self.layer1_stride, padding=self.layer1_padding)\n",
    "        self.dropout = nn.Dropout(0.05)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(self.layer1_filters)\n",
    "        self.pooling = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(self.layer1_filters, self.layer2_filters, self.layer2_kernel_size, stride=self.layer2_stride, padding=self.layer2_padding)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(self.layer2_filters)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc_inputs = int(self.layer2_filters * (self.layer2_dim_h // 2) * (self.layer2_dim_w // 2))\n",
    "\n",
    "        self.lin1 = nn.Linear(self.fc_inputs, self.fc_layer_size)\n",
    "\n",
    "        self.lin2 = nn.Linear(self.fc_layer_size, self.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.pooling(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.pooling2(x)\n",
    "        # flatten convolutional layer into vector\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def get_category(output):\n",
    "    return torch.argmax(torch.abs(output))\n",
    "    #return torch.argmax(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG16, self).__init__()\n",
    "        fc_layer_size = 4096\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, fc_layer_size),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(fc_layer_size, fc_layer_size),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(fc_layer_size, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (32, 32, 3)\n",
      "found 11945 items!\n",
      "x dim: (11945, 32, 32, 3)\n",
      "reading directory Abra with 71 items\n",
      "reading directory Aerodactyl with 69 items\n",
      "processed 100/69\n",
      "reading directory Alakazam with 106 items\n",
      "processed 200/106\n",
      "reading directory Arbok with 91 items\n",
      "processed 300/91\n",
      "reading directory Arcanine with 66 items\n",
      "processed 400/66\n",
      "reading directory Articuno with 79 items\n",
      "reading directory Beedrill with 47 items\n",
      "processed 500/47\n",
      "reading directory Bellsprout with 66 items\n",
      "reading directory Blastoise with 57 items\n",
      "processed 600/57\n",
      "reading directory Bulbasaur with 50 items\n",
      "processed 700/50\n",
      "reading directory Butterfree with 75 items\n",
      "reading directory Caterpie with 65 items\n",
      "processed 800/65\n",
      "reading directory Chansey with 84 items\n",
      "processed 900/84\n",
      "reading directory Charizard with 88 items\n",
      "processed 1000/88\n",
      "reading directory Charmander with 111 items\n",
      "processed 1100/111\n",
      "reading directory Charmeleon with 44 items\n",
      "reading directory Clefable with 80 items\n",
      "processed 1200/80\n",
      "reading directory Clefairy with 60 items\n",
      "processed 1300/60\n",
      "reading directory Cloyster with 70 items\n",
      "reading directory Cubone with 79 items\n",
      "processed 1400/79\n",
      "reading directory Dewgong with 66 items\n",
      "processed 1500/66\n",
      "reading directory Diglett with 90 items\n",
      "processed 1600/90\n",
      "reading directory Ditto with 56 items\n",
      "reading directory Dodrio with 68 items\n",
      "processed 1700/68\n",
      "reading directory Doduo with 86 items\n",
      "processed 1800/86\n",
      "reading directory Dragonair with 89 items\n",
      "processed 1900/89\n",
      "reading directory Dragonite with 80 items\n",
      "reading directory Dratini with 71 items\n",
      "processed 2000/71\n",
      "reading directory Drowzee with 65 items\n",
      "processed 2100/65\n",
      "reading directory Dugtrio with 78 items\n",
      "processed 2200/78\n",
      "reading directory Eevee with 102 items\n",
      "processed 2300/102\n",
      "reading directory Ekans with 43 items\n",
      "reading directory Electabuzz with 72 items\n",
      "processed 2400/72\n",
      "reading directory Electrode with 90 items\n",
      "processed 2500/90\n",
      "reading directory Exeggcute with 61 items\n",
      "reading directory Exeggutor with 67 items\n",
      "processed 2600/67\n",
      "reading directory Farfetchd with 71 items\n",
      "processed 2700/71\n",
      "reading directory Fearow with 80 items\n",
      "reading directory Flareon with 87 items\n",
      "processed 2800/87\n",
      "reading directory Gastly with 103 items\n",
      "processed 2900/103\n",
      "reading directory Gengar with 134 items\n",
      "processed 3000/134\n",
      "processed 3100/134\n",
      "reading directory Geodude with 86 items\n",
      "processed 3200/86\n",
      "reading directory Gloom with 99 items\n",
      "processed 3300/99\n",
      "reading directory Golbat with 90 items\n",
      "reading directory Goldeen with 89 items\n",
      "processed 3400/89\n",
      "reading directory Golduck with 78 items\n",
      "processed 3500/78\n",
      "reading directory Golem with 88 items\n",
      "processed 3600/88\n",
      "reading directory Graveler with 68 items\n",
      "processed 3700/68\n",
      "reading directory Grimer with 93 items\n",
      "processed 3800/93\n",
      "reading directory Growlithe with 111 items\n",
      "processed 3900/111\n",
      "reading directory Gyarados with 134 items\n",
      "processed 4000/134\n",
      "reading directory Haunter with 74 items\n",
      "processed 4100/74\n",
      "reading directory Hitmonchan with 69 items\n",
      "reading directory Hitmonlee with 72 items\n",
      "processed 4200/72\n",
      "reading directory Horsea with 81 items\n",
      "processed 4300/81\n",
      "reading directory Hypno with 80 items\n",
      "processed 4400/80\n",
      "reading directory Ivysaur with 88 items\n",
      "processed 4500/88\n",
      "reading directory Jigglypuff with 76 items\n",
      "reading directory Jolteon with 87 items\n",
      "processed 4600/87\n",
      "reading directory Jynx with 84 items\n",
      "processed 4700/84\n",
      "reading directory Kabuto with 77 items\n",
      "processed 4800/77\n",
      "reading directory Kabutops with 70 items\n",
      "processed 4900/70\n",
      "reading directory Kadabra with 107 items\n",
      "processed 5000/107\n",
      "reading directory Kakuna with 60 items\n",
      "reading directory Kangaskhan with 72 items\n",
      "processed 5100/72\n",
      "reading directory Kingler with 69 items\n",
      "processed 5200/69\n",
      "reading directory Koffing with 76 items\n",
      "reading directory Krabby with 85 items\n",
      "processed 5300/85\n",
      "reading directory Lapras with 82 items\n",
      "processed 5400/82\n",
      "reading directory Lickitung with 94 items\n",
      "processed 5500/94\n",
      "reading directory Machamp with 67 items\n",
      "processed 5600/67\n",
      "reading directory Machoke with 63 items\n",
      "reading directory Machop with 79 items\n",
      "processed 5700/79\n",
      "reading directory Magikarp with 84 items\n",
      "processed 5800/84\n",
      "reading directory Magmar with 74 items\n",
      "processed 5900/74\n",
      "reading directory Magnemite with 74 items\n",
      "reading directory Magneton with 64 items\n",
      "processed 6000/64\n",
      "reading directory Mankey with 102 items\n",
      "processed 6100/102\n",
      "reading directory Marowak with 66 items\n",
      "processed 6200/66\n",
      "reading directory Meowth with 84 items\n",
      "processed 6300/84\n",
      "reading directory Metapod with 82 items\n",
      "reading directory Mew with 71 items\n",
      "processed 6400/71\n",
      "reading directory Mewtwo with 99 items\n",
      "processed 6500/99\n",
      "reading directory Moltres with 82 items\n",
      "processed 6600/82\n",
      "reading directory Mr.Mime with 67 items\n",
      "processed 6700/67\n",
      "reading directory Muk with 97 items\n",
      "processed 6800/97\n",
      "reading directory Nidoking with 106 items\n",
      "processed 6900/106\n",
      "reading directory Nidoqueen with 90 items\n",
      "processed 7000/90\n",
      "reading directory Nidoran-f with 66 items\n",
      "reading directory Nidoran-m with 84 items\n",
      "processed 7100/84\n",
      "reading directory Nidorina with 84 items\n",
      "processed 7200/84\n",
      "reading directory Nidorino with 95 items\n",
      "processed 7300/95\n",
      "reading directory Ninetales with 69 items\n",
      "processed 7400/69\n",
      "reading directory Oddish with 66 items\n",
      "reading directory Omanyte with 72 items\n",
      "processed 7500/72\n",
      "reading directory Omastar with 65 items\n",
      "processed 7600/65\n",
      "reading directory Onix with 64 items\n",
      "reading directory Paras with 87 items\n",
      "processed 7700/87\n",
      "reading directory Parasect with 66 items\n",
      "processed 7800/66\n",
      "reading directory Persian with 68 items\n",
      "reading directory Pidgeot with 108 items\n",
      "processed 7900/108\n",
      "processed 8000/108\n",
      "reading directory Pidgeotto with 76 items\n",
      "reading directory Pidgey with 87 items\n",
      "processed 8100/87\n",
      "reading directory Pikachu with 103 items\n",
      "processed 8200/103\n",
      "reading directory Pinsir with 76 items\n",
      "processed 8300/76\n",
      "reading directory Poliwag with 109 items\n",
      "processed 8400/109\n",
      "reading directory Poliwhirl with 105 items\n",
      "processed 8500/105\n",
      "reading directory Poliwrath with 95 items\n",
      "processed 8600/95\n",
      "reading directory Ponyta with 109 items\n",
      "processed 8700/109\n",
      "reading directory Porygon with 62 items\n",
      "processed 8800/62\n",
      "reading directory Primeape with 103 items\n",
      "processed 8900/103\n",
      "reading directory Psyduck with 124 items\n",
      "processed 9000/124\n",
      "reading directory Raichu with 84 items\n",
      "processed 9100/84\n",
      "reading directory Rapidash with 104 items\n",
      "processed 9200/104\n",
      "reading directory Raticate with 70 items\n",
      "processed 9300/70\n",
      "reading directory Rattata with 41 items\n",
      "reading directory Rhydon with 72 items\n",
      "processed 9400/72\n",
      "reading directory Rhyhorn with 66 items\n",
      "reading directory Sandshrew with 64 items\n",
      "processed 9500/64\n",
      "reading directory Sandslash with 90 items\n",
      "processed 9600/90\n",
      "reading directory Scyther with 79 items\n",
      "processed 9700/79\n",
      "reading directory Seadra with 70 items\n",
      "reading directory Seaking with 75 items\n",
      "processed 9800/75\n",
      "reading directory Seel with 80 items\n",
      "processed 9900/80\n",
      "reading directory Shellder with 85 items\n",
      "processed 10000/85\n",
      "reading directory Slowbro with 75 items\n",
      "processed 10100/75\n",
      "reading directory Slowpoke with 65 items\n",
      "reading directory Snorlax with 84 items\n",
      "processed 10200/84\n",
      "reading directory Spearow with 53 items\n",
      "processed 10300/53\n",
      "reading directory Squirtle with 59 items\n",
      "reading directory Starmie with 61 items\n",
      "processed 10400/61\n",
      "reading directory Staryu with 64 items\n",
      "reading directory Tangela with 76 items\n",
      "processed 10500/76\n",
      "reading directory Tauros with 60 items\n",
      "processed 10600/60\n",
      "reading directory Tentacool with 86 items\n",
      "processed 10700/86\n",
      "reading directory Tentacruel with 69 items\n",
      "reading directory Vaporeon with 105 items\n",
      "processed 10800/105\n",
      "reading directory Venomoth with 59 items\n",
      "processed 10900/59\n",
      "reading directory Venonat with 85 items\n",
      "processed 11000/85\n",
      "reading directory Venusaur with 52 items\n",
      "reading directory Victreebel with 94 items\n",
      "processed 11100/94\n",
      "reading directory Vileplume with 72 items\n",
      "processed 11200/72\n",
      "reading directory Voltorb with 100 items\n",
      "processed 11300/100\n",
      "reading directory Vulpix with 68 items\n",
      "processed 11400/68\n",
      "reading directory Wartortle with 85 items\n",
      "processed 11500/85\n",
      "reading directory Weedle with 43 items\n",
      "reading directory Weepinbell with 84 items\n",
      "processed 11600/84\n",
      "reading directory Weezing with 72 items\n",
      "processed 11700/72\n",
      "reading directory Wigglytuff with 98 items\n",
      "reading directory Zapdos with 86 items\n",
      "processed 11800/86\n",
      "reading directory Zubat with 60 items\n",
      "processed 11900/60\n",
      "label statistics: [ 71.  69. 106.  91.  66.  79.  47.  66.  57.  50.  75.  65.  84.  88.\n",
      " 111.  44.  80.  60.  70.  79.  66.  90.  56.  68.  86.  89.  80.  71.\n",
      "  65.  78. 102.  43.  72.  90.  61.  67.  71.  80.  87. 103. 134.  86.\n",
      "  99.  90.  89.  78.  88.  68.  93. 111. 134.  74.  69.  72.  81.  80.\n",
      "  88.  76.  87.  84.  77.  70. 107.  60.  72.  69.  76.  85.  82.  94.\n",
      "  67.  63.  79.  84.  74.  74.  64. 102.  66.  84.  82.  71.  99.  82.\n",
      "  67.  97. 106.  90.  66.  84.  84.  95.  69.  66.  72.  65.  64.  87.\n",
      "  66.  68. 108.  76.  87. 103.  76. 109. 105.  95. 109.  62. 103. 124.\n",
      "  84. 104.  70.  41.  72.  66.  64.  90.  79.  70.  75.  80.  85.  75.\n",
      "  65.  84.  53.  59.  61.  64.  76.  60.  86.  69. 105.  59.  85.  52.\n",
      "  94.  72. 100.  68.  85.  43.  84.  72.  98.  86.  60.]\n",
      "finished feature import\n",
      "X shape: (11945, 3, 32, 32)\n",
      "Y Shape: (11945, 151)\n",
      "X train shape: torch.Size([9556, 3, 32, 32])\n",
      "Y Shape: torch.Size([9556])\n",
      "indim: (3, 32, 32) outdim: (151,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RUNNER\n",
    "\"\"\"\n",
    "\n",
    "# directory containing original images\n",
    "raw_data_dir = '../../Data/pokemon/PokemonData'\n",
    "\n",
    "# directory to save processed numpy arrays\n",
    "processed_data_dir = '../../Data/pokemon/PokemonDataProcessed'\n",
    "\n",
    "# specifies which categories to read from. Leave as None to read from all\n",
    "folders = ['Pikachu','Ditto']\n",
    "folders = None\n",
    "\n",
    "#preprocess(raw_data_dir, processed_data_dir)\n",
    "\n",
    "X, Y = import_images(processed_data_dir, folders)\n",
    "X = np.moveaxis(X, -1, 1)\n",
    "print(f'X shape: {X.shape}\\nY Shape: {Y.shape}')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "in_dim = X[0].shape\n",
    "num_classes = Y[0].shape\n",
    "\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "x_train = torch.from_numpy(x_train)\n",
    "#x_train = torch.unsqueeze(x_train, 2)\n",
    "x_train = x_train.type(torch.float32).to(device)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "#y_train = torch.unsqueeze(y_train, 1)\n",
    "y_train = y_train.type(torch.LongTensor).to(device)\n",
    "\n",
    "x_test = torch.from_numpy(x_test)\n",
    "#x_test = torch.unsqueeze(x_test, 2)\n",
    "x_test = x_test.type(torch.float32).to(device)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "#y_test = torch.unsqueeze(y_test, 1)\n",
    "y_test = y_test.type(torch.LongTensor).to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(f'X train shape: {x_train.shape}\\nY Shape: {y_train.shape}')\n",
    "print(f'indim: {in_dim} outdim: {num_classes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training\n",
      "\tTraining epoch 0 Accuracy: 1.1615738802846378%\n",
      "testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eggyr\\anaconda3\\envs\\pytorch3d\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttesting accuracy: 1.4650481372959396%\n",
      "epoch 1\n",
      "training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epoch):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     test(cnn, test_loader, device)\n",
      "Cell \u001b[1;32mIn[134], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, loader, optimizer, epoch, device)\u001b[0m\n\u001b[0;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# compute gradients and make updates\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     35\u001b[0m pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\eggyr\\anaconda3\\envs\\pytorch3d\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eggyr\\anaconda3\\envs\\pytorch3d\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.NLLLoss()\n",
    "momentum = 0.9\n",
    "cnn = CNN(in_dim, num_classes[0]).to(device)\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "train_batch_size = 100\n",
    "test_batch_size = 10\n",
    "\n",
    "# Create Dataset objects, then create torch dataloader\n",
    "train_dataset = SimpleDataset(x_train, y_train)\n",
    "test_dataset = SimpleDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "def train(net, loader, optimizer, epoch, device):\n",
    "    print(f'training')\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # clear up gradients for backprop\n",
    "        optimizer.zero_grad()\n",
    "        output = F.log_softmax(net(data), dim=1)\n",
    "        #print(f'output: {output} target: {target}')\n",
    "        # use NLL loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradients and make updates\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += (pred.eq(target.data.view_as(pred)).sum().item())\n",
    "\n",
    "    print(f'\\tTraining epoch {epoch} Accuracy: {100 * correct / len(loader.dataset)}%')\n",
    "\n",
    "\n",
    "def test(net, loader, device):\n",
    "    print(f'testing')\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = net(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += (pred.eq(target.data.view_as(pred)).sum().item())\n",
    "\n",
    "            total = total + 1\n",
    "    accuracy = 100 * correct / len(loader.dataset)\n",
    "    print(f'\\ttesting accuracy: {accuracy}%')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "n_epoch = 20\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print(f'epoch {epoch}')\n",
    "    train(cnn, train_loader, optimizer, epoch, device)\n",
    "    test(cnn, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "criterion = nn.NLLLoss()\n",
    "momentum = 0.9\n",
    "cnn = VGG16(num_classes[0]).to(device)\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "train_batch_size = 100\n",
    "test_batch_size = 10\n",
    "\n",
    "# Create Dataset objects, then create torch dataloader\n",
    "train_dataset = SimpleDataset(x_train, y_train)\n",
    "test_dataset = SimpleDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "def train(net, loader, optimizer, epoch, device):\n",
    "    print(f'training')\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # clear up gradients for backprop\n",
    "        optimizer.zero_grad()\n",
    "        output = F.log_softmax(net(data), dim=1)\n",
    "        #print(f'output: {output} target: {target}')\n",
    "        # use NLL loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradients and make updates\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += (pred.eq(target.data.view_as(pred)).sum().item())\n",
    "\n",
    "    print(f'\\tTraining epoch {epoch} Accuracy: {100 * correct / len(loader.dataset)}%')\n",
    "\n",
    "\n",
    "def test(net, loader, device):\n",
    "    print(f'testing')\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = net(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += (pred.eq(target.data.view_as(pred)).sum().item())\n",
    "\n",
    "            total = total + 1\n",
    "    accuracy = 100 * correct / len(loader.dataset)\n",
    "    print(f'\\ttesting accuracy: {accuracy}%')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "n_epoch = 100\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print(f'epoch {epoch}')\n",
    "    train(cnn, train_loader, optimizer, epoch, device)\n",
    "    test(cnn, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
