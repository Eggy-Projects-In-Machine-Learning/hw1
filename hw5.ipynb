{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will classify 151 different pokemons. A total of 11,945 pokemon images are used, with around 50-150 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import Augmentor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PREPROCESSING HELPER FUNCTION\n",
    "\n",
    "formats image files and converts into numpy arrays of the same shape, then saves to specified location\n",
    "\n",
    "Returns 0 upon success, otherwise returns 1 (unsuccessful may be due to undesirable properties such as\n",
    "large aspect ratio)\n",
    "\"\"\"\n",
    "\n",
    "def process_file(file_path, processed_file_path, target_size = 32, aspect_ratio_thres = 1.3):\n",
    "    with Image.open(file_path) as image:\n",
    "        # crop out the longer dimension so it's square\n",
    "        width, height = image.size\n",
    "        new_size = min(width, height)\n",
    "        if new_size * aspect_ratio_thres < max(width, height):\n",
    "            # print(f'skipped due to aspect ratio too high')\n",
    "            return 1\n",
    "        left = (width - new_size) / 2\n",
    "        top = (height - new_size) / 2\n",
    "        right = (width + new_size) / 2\n",
    "        bottom = (height + new_size) / 2\n",
    "        image = image.crop((left, top, right, bottom))\n",
    "        \n",
    "        # resize\n",
    "        image = image.resize((target_size, target_size))\n",
    "\n",
    "        # convert the image to RGB\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        # convert to numpy array\n",
    "        img_array = np.array(image)\n",
    "\n",
    "        # print(f'processed array shape: {img_array.shape}')\n",
    "        if img_array.shape != (target_size, target_size, 3):\n",
    "            print(f'error! wrong shape {img_array.shape}')\n",
    "        \n",
    "        # save to file\n",
    "        np.save(processed_file_path, img_array)\n",
    "\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MAIN PIPELINE 1\n",
    "\n",
    "preprocesses data by reading from directory and saves processed data into another directory with same structure.\n",
    "\"\"\"\n",
    "\n",
    "def preprocess(raw_data_dir, processed_data_dir, imgsize, augmentation=False, augmentation_path=None, processed_augmentation_path=None, augmentation_path_relative=None):\n",
    "    # Create the processed_data directory if it doesn't exist\n",
    "    if not os.path.exists(processed_data_dir):\n",
    "        os.makedirs(processed_data_dir)\n",
    "\n",
    "    if augmentation:\n",
    "        if not os.path.exists(augmentation_path):\n",
    "            os.makedirs(augmentation_path)   \n",
    "\n",
    "        if not os.path.exists(processed_augmentation_path):\n",
    "            os.makedirs(processed_augmentation_path)\n",
    "\n",
    "    # List all subfolders in raw_data\n",
    "    for subdir in os.listdir(raw_data_dir):\n",
    "        print(f'reading directory {subdir}')\n",
    "        raw_subdir_path = os.path.join(raw_data_dir, subdir)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if not os.path.isdir(raw_subdir_path):\n",
    "            continue\n",
    "        if len(os.listdir(raw_subdir_path)) == 0:\n",
    "            print('WARNING: EMPTY DIRECTORY!!!')\n",
    "            continue\n",
    "        processed_subdir_path = os.path.join(processed_data_dir, subdir)\n",
    "\n",
    "        # Create the subfolder in processed_data if it doesn't exist\n",
    "        if not os.path.exists(processed_subdir_path):\n",
    "            os.makedirs(processed_subdir_path)\n",
    "\n",
    "        if augmentation:\n",
    "            augmentation_subdir_path = os.path.join(augmentation_path, subdir)\n",
    "            augmentation_subdir_relative = os.path.join(augmentation_path_relative, subdir)\n",
    "            processed_augmentation_subdir_path = os.path.join(processed_augmentation_path, subdir)\n",
    "                \n",
    "            if not os.path.exists(augmentation_subdir_path):\n",
    "                os.makedirs(augmentation_subdir_path)   \n",
    "\n",
    "            if not os.path.exists(processed_augmentation_subdir_path):\n",
    "                os.makedirs(processed_augmentation_subdir_path)\n",
    "        \n",
    "        count = 0\n",
    "        processed_count = 0\n",
    "        total = len(os.listdir(raw_subdir_path))\n",
    "\n",
    "        if augmentation:\n",
    "            p = Augmentor.Pipeline(raw_subdir_path, augmentation_subdir_relative)\n",
    "            p.rotate(probability=0.7, max_left_rotation=20, max_right_rotation=20)\n",
    "            p.flip_left_right(probability=0.7)\n",
    "            p.zoom_random(probability=0.8, percentage_area=0.9)\n",
    "            p.sample(total)\n",
    "\n",
    "        # Process each file in the subdirectory\n",
    "        for filename in os.listdir(raw_subdir_path):\n",
    "            file_path = os.path.join(raw_subdir_path, filename)\n",
    "            processed_file_path = os.path.join(processed_subdir_path, filename)\n",
    "            \n",
    "            # Process the file\n",
    "            return_code = process_file(file_path, processed_file_path, imgsize)\n",
    "            count += 1\n",
    "            if return_code == 0:\n",
    "                processed_count += 1\n",
    "            if count % 100 == 0 or count == total:\n",
    "                print(f'traversed {count} / {total}, processed {processed_count}')\n",
    "\n",
    "        if not augmentation:\n",
    "            continue\n",
    "        \n",
    "        for filename in os.listdir(augmentation_subdir_path):\n",
    "            file_path = os.path.join(augmentation_subdir_path, filename)\n",
    "            processed_file_path = os.path.join(processed_augmentation_subdir_path, filename)\n",
    "            \n",
    "            # Process the file\n",
    "            return_code = process_file(file_path, processed_file_path, imgsize)\n",
    "            count += 1\n",
    "            if return_code == 0:\n",
    "                processed_count += 1\n",
    "            if count % 100 == 0 or count == total:\n",
    "                print(f'traversed {count} / {total}, processed {processed_count}')\n",
    "                \n",
    "    print('finished preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMPORTS PROCESSED IMAGES INTO X AND Y\n",
    "\"\"\"\n",
    "\n",
    "def import_images(processed_data_dir, folders, include_augmented=False, augmentation_data_dir=None):\n",
    "    total_items = 0\n",
    "    total_categories = 0\n",
    "    image_dim = None\n",
    "\n",
    "    # List all subfolders\n",
    "    for subdir in os.listdir(processed_data_dir):\n",
    "        if folders is not None and subdir not in folders:\n",
    "            continue\n",
    "\n",
    "        subdir_path = os.path.join(processed_data_dir, subdir)\n",
    "        # Check if it's a directory\n",
    "        if not os.path.isdir(subdir_path):\n",
    "            continue\n",
    "\n",
    "        total_categories += 1\n",
    "        if total_items == 0:\n",
    "            for filename in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, filename)\n",
    "                data = np.load(file_path)\n",
    "                print(f'data shape: {data.shape}')\n",
    "                image_dim = data.shape\n",
    "                break\n",
    "        total_items += len(os.listdir(subdir_path))\n",
    "        \n",
    "    if include_augmented:\n",
    "        # List all subfolders for augmentation\n",
    "        for subdir in os.listdir(augmentation_data_dir):\n",
    "            if folders is not None and subdir not in folders:\n",
    "                continue\n",
    "\n",
    "            subdir_path = os.path.join(augmentation_data_dir, subdir)\n",
    "            # Check if it's a directory\n",
    "            if not os.path.isdir(subdir_path):\n",
    "                continue\n",
    "            total_items += len(os.listdir(subdir_path))\n",
    "\n",
    "    print(f'found {total_items} items!')\n",
    "        \n",
    "    X = np.zeros((total_items, *image_dim))\n",
    "    print(f'x dim: {X.shape}')\n",
    "    Y = np.zeros((total_items, total_categories))\n",
    "    \n",
    "    category_counter = 0\n",
    "    item_counter = 0\n",
    "\n",
    "    # List all subfolders\n",
    "    for subdir in os.listdir(processed_data_dir):\n",
    "        if folders is not None and subdir not in folders:\n",
    "            continue\n",
    "        \n",
    "        subdir_path = os.path.join(processed_data_dir, subdir)\n",
    "        print(f'reading directory {subdir} with {len(os.listdir(subdir_path))} items')\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if not os.path.isdir(subdir_path):\n",
    "            continue\n",
    "        \n",
    "        # Process each file in the subdirectory\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            file_path = os.path.join(subdir_path, filename)\n",
    "            data = np.load(file_path)\n",
    "            \n",
    "            X[item_counter] = data\n",
    "            Y[item_counter][category_counter] = 1\n",
    "            item_counter += 1\n",
    "\n",
    "            if item_counter % 100 == 0:\n",
    "                print(f'processed {item_counter}/{len(os.listdir(subdir_path))}')\n",
    "\n",
    "        category_counter += 1\n",
    "\n",
    "    category_counter = 0\n",
    "    if include_augmented:\n",
    "        # List all subfolders for augmentation\n",
    "        for subdir in os.listdir(augmentation_data_dir):\n",
    "            if folders is not None and subdir not in folders:\n",
    "                continue\n",
    "\n",
    "            subdir_path = os.path.join(augmentation_data_dir, subdir)\n",
    "            # Check if it's a directory\n",
    "            if not os.path.isdir(subdir_path):\n",
    "                continue\n",
    "            print(f'reading augmented directory {subdir} with {len(os.listdir(subdir_path))} items')\n",
    "        \n",
    "            # Check if it's a directory\n",
    "            if not os.path.isdir(subdir_path):\n",
    "                continue\n",
    "            \n",
    "            # Process each file in the subdirectory\n",
    "            for filename in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, filename)\n",
    "                data = np.load(file_path)\n",
    "                \n",
    "                X[item_counter] = data\n",
    "                Y[item_counter][category_counter] = 1\n",
    "                item_counter += 1\n",
    "\n",
    "                if item_counter % 100 == 0:\n",
    "                    print(f'processed {item_counter}/{len(os.listdir(subdir_path))}')\n",
    "\n",
    "        category_counter += 1\n",
    "\n",
    "    print(f'processed {total_items} items')\n",
    "    print(f'label statistics: {np.sum(Y, axis=0)} summing to {np.sum(Y)}')\n",
    "    print('finished feature import')\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.num_classes = num_classes        \n",
    "\n",
    "        self.fc_layer_size = 1000\n",
    "\n",
    "        self.layer1_filters = 32\n",
    "\n",
    "        self.layer1_kernel_size = (4,4)\n",
    "        self.layer1_stride = 1\n",
    "        self.layer1_padding = 0\n",
    "\n",
    "        self.layer2_filters = 64\n",
    "\n",
    "        self.layer2_kernel_size = (2,2)\n",
    "        self.layer2_stride = 1\n",
    "        self.layer2_padding = 0\n",
    "\n",
    "        self.layer1_dim_h = (self.in_dim[1] - self.layer1_kernel_size[0]) / self.layer1_stride + 1\n",
    "        self.layer1_dim_w = (self.in_dim[2] - self.layer1_kernel_size[1]) / self.layer1_stride + 1        \n",
    "\n",
    "        self.layer2_dim_h = ((self.layer1_dim_h // 2) - self.layer2_kernel_size[0]) / self.layer2_stride + 1\n",
    "        self.layer2_dim_w = ((self.layer1_dim_w // 2)  - self.layer2_kernel_size[1]) / self.layer2_stride + 1        \n",
    "\n",
    "        print(f'layer2_dim_h {self.layer2_dim_h}\\nlayer2_dim_w {self.layer2_dim_w}')\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.layer1_filters, self.layer1_kernel_size, stride=self.layer1_stride, padding=self.layer1_padding)\n",
    "        self.dropout = nn.Dropout(0.05)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(self.layer1_filters)\n",
    "        self.pooling = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(self.layer1_filters, self.layer2_filters, self.layer2_kernel_size, stride=self.layer2_stride, padding=self.layer2_padding)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(self.layer2_filters)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc_inputs = int(self.layer2_filters * (self.layer2_dim_h // 2) * (self.layer2_dim_w // 2))\n",
    "\n",
    "        self.lin1 = nn.Linear(self.fc_inputs, self.fc_layer_size)\n",
    "\n",
    "        self.lin2 = nn.Linear(self.fc_layer_size, self.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.pooling(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.pooling2(x)\n",
    "        # flatten convolutional layer into vector\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def get_category(output):\n",
    "    return torch.argmax(torch.abs(output))\n",
    "    #return torch.argmax(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, in_dim, num_classes):\n",
    "        super(VGG16, self).__init__()\n",
    "        fc_layer_size = 4096\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(int(in_dim[1] * in_dim[2] * 0.5), fc_layer_size),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(fc_layer_size, fc_layer_size),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(fc_layer_size, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def create_test_folder(raw_data_dir, test_data_dir):\n",
    "    if not os.path.exists(test_data_dir):\n",
    "        os.makedirs(test_data_dir)   \n",
    "\n",
    "    for subdir in os.listdir(raw_data_dir):\n",
    "        print(f'reading directory {subdir}')\n",
    "        raw_subdir_path = os.path.join(raw_data_dir, subdir)\n",
    "        test_subdir_path = os.path.join(test_data_dir, subdir)\n",
    "        # Check if it's a directory\n",
    "        if not os.path.isdir(raw_subdir_path):\n",
    "            continue\n",
    "        if len(os.listdir(raw_subdir_path)) == 0:\n",
    "            print('WARNING: EMPTY DIRECTORY!!!')\n",
    "            continue\n",
    "        \n",
    "        # Create the subfolder in processed_data if it doesn't exist\n",
    "        if not os.path.exists(test_subdir_path):\n",
    "            os.makedirs(test_subdir_path)\n",
    "\n",
    "        test_items = np.random.choice(np.arange(len(os.listdir(raw_subdir_path))), size=int(len(os.listdir(raw_subdir_path)) / 10), replace=False)\n",
    "        \n",
    "        files = [f for f in os.listdir(raw_subdir_path) if os.path.isfile(os.path.join(raw_subdir_path, f))]\n",
    "        files_to_move = np.array(files)[test_items]\n",
    "\n",
    "        for file_name in files_to_move:\n",
    "            source_path = os.path.join(raw_subdir_path, file_name)\n",
    "            target_path = os.path.join(test_subdir_path, file_name)\n",
    "            shutil.move(source_path, target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (64, 64, 3)\n",
      "found 10818 items!\n",
      "x dim: (10818, 64, 64, 3)\n",
      "reading directory Abra with 64 items\n",
      "reading directory Aerodactyl with 63 items\n",
      "processed 100/63\n",
      "reading directory Alakazam with 96 items\n",
      "processed 200/96\n",
      "reading directory Arbok with 82 items\n",
      "processed 300/82\n",
      "reading directory Arcanine with 60 items\n",
      "reading directory Articuno with 72 items\n",
      "processed 400/72\n",
      "reading directory Beedrill with 43 items\n",
      "reading directory Bellsprout with 60 items\n",
      "processed 500/60\n",
      "reading directory Blastoise with 52 items\n",
      "reading directory Bulbasaur with 45 items\n",
      "processed 600/45\n",
      "reading directory Butterfree with 68 items\n",
      "processed 700/68\n",
      "reading directory Caterpie with 59 items\n",
      "reading directory Chansey with 76 items\n",
      "processed 800/76\n",
      "reading directory Charizard with 80 items\n",
      "processed 900/80\n",
      "reading directory Charmander with 100 items\n",
      "processed 1000/100\n",
      "reading directory Charmeleon with 40 items\n",
      "reading directory Clefable with 72 items\n",
      "processed 1100/72\n",
      "reading directory Clefairy with 54 items\n",
      "reading directory Cloyster with 63 items\n",
      "processed 1200/63\n",
      "reading directory Cubone with 72 items\n",
      "processed 1300/72\n",
      "reading directory Dewgong with 60 items\n",
      "reading directory Diglett with 81 items\n",
      "processed 1400/81\n",
      "reading directory Ditto with 51 items\n",
      "processed 1500/51\n",
      "reading directory Dodrio with 62 items\n",
      "reading directory Doduo with 78 items\n",
      "processed 1600/78\n",
      "reading directory Dragonair with 81 items\n",
      "processed 1700/81\n",
      "reading directory Dragonite with 72 items\n",
      "processed 1800/72\n",
      "reading directory Dratini with 64 items\n",
      "reading directory Drowzee with 59 items\n",
      "processed 1900/59\n",
      "reading directory Dugtrio with 71 items\n",
      "processed 2000/71\n",
      "reading directory Eevee with 92 items\n",
      "reading directory Ekans with 39 items\n",
      "processed 2100/39\n",
      "reading directory Electabuzz with 65 items\n",
      "reading directory Electrode with 81 items\n",
      "processed 2200/81\n",
      "reading directory Exeggcute with 55 items\n",
      "processed 2300/55\n",
      "reading directory Exeggutor with 61 items\n",
      "reading directory Farfetchd with 64 items\n",
      "processed 2400/64\n",
      "reading directory Fearow with 72 items\n",
      "processed 2500/72\n",
      "reading directory Flareon with 79 items\n",
      "processed 2600/79\n",
      "reading directory Gastly with 93 items\n",
      "processed 2700/93\n",
      "reading directory Gengar with 121 items\n",
      "processed 2800/121\n",
      "reading directory Geodude with 78 items\n",
      "processed 2900/78\n",
      "reading directory Gloom with 90 items\n",
      "reading directory Golbat with 81 items\n",
      "processed 3000/81\n",
      "reading directory Goldeen with 81 items\n",
      "processed 3100/81\n",
      "reading directory Golduck with 71 items\n",
      "processed 3200/71\n",
      "reading directory Golem with 80 items\n",
      "processed 3300/80\n",
      "reading directory Graveler with 62 items\n",
      "reading directory Grimer with 84 items\n",
      "processed 3400/84\n",
      "reading directory Growlithe with 100 items\n",
      "processed 3500/100\n",
      "reading directory Gyarados with 121 items\n",
      "processed 3600/121\n",
      "reading directory Haunter with 67 items\n",
      "processed 3700/67\n",
      "reading directory Hitmonchan with 63 items\n",
      "processed 3800/63\n",
      "reading directory Hitmonlee with 65 items\n",
      "reading directory Horsea with 73 items\n",
      "processed 3900/73\n",
      "reading directory Hypno with 72 items\n",
      "processed 4000/72\n",
      "reading directory Ivysaur with 80 items\n",
      "reading directory Jigglypuff with 69 items\n",
      "processed 4100/69\n",
      "reading directory Jolteon with 79 items\n",
      "processed 4200/79\n",
      "reading directory Jynx with 76 items\n",
      "processed 4300/76\n",
      "reading directory Kabuto with 70 items\n",
      "reading directory Kabutops with 63 items\n",
      "processed 4400/63\n",
      "reading directory Kadabra with 97 items\n",
      "processed 4500/97\n",
      "reading directory Kakuna with 54 items\n",
      "reading directory Kangaskhan with 65 items\n",
      "processed 4600/65\n",
      "reading directory Kingler with 63 items\n",
      "processed 4700/63\n",
      "reading directory Koffing with 69 items\n",
      "reading directory Krabby with 77 items\n",
      "processed 4800/77\n",
      "reading directory Lapras with 74 items\n",
      "processed 4900/74\n",
      "reading directory Lickitung with 85 items\n",
      "processed 5000/85\n",
      "reading directory Machamp with 61 items\n",
      "reading directory Machoke with 57 items\n",
      "processed 5100/57\n",
      "reading directory Machop with 72 items\n",
      "processed 5200/72\n",
      "reading directory Magikarp with 76 items\n",
      "reading directory Magmar with 67 items\n",
      "processed 5300/67\n",
      "reading directory Magnemite with 67 items\n",
      "processed 5400/67\n",
      "reading directory Magneton with 58 items\n",
      "reading directory Mankey with 92 items\n",
      "processed 5500/92\n",
      "reading directory Marowak with 60 items\n",
      "processed 5600/60\n",
      "reading directory Meowth with 76 items\n",
      "processed 5700/76\n",
      "reading directory Metapod with 74 items\n",
      "reading directory Mew with 64 items\n",
      "processed 5800/64\n",
      "reading directory Mewtwo with 90 items\n",
      "processed 5900/90\n",
      "reading directory Moltres with 74 items\n",
      "processed 6000/74\n",
      "reading directory Mr.Mime with 61 items\n",
      "reading directory Muk with 88 items\n",
      "processed 6100/88\n",
      "reading directory Nidoking with 96 items\n",
      "processed 6200/96\n",
      "reading directory Nidoqueen with 81 items\n",
      "processed 6300/81\n",
      "reading directory Nidoran-f with 60 items\n",
      "processed 6400/60\n",
      "reading directory Nidoran-m with 76 items\n",
      "reading directory Nidorina with 76 items\n",
      "processed 6500/76\n",
      "reading directory Nidorino with 86 items\n",
      "processed 6600/86\n",
      "reading directory Ninetales with 63 items\n",
      "processed 6700/63\n",
      "reading directory Oddish with 60 items\n",
      "reading directory Omanyte with 65 items\n",
      "processed 6800/65\n",
      "reading directory Omastar with 59 items\n",
      "reading directory Onix with 58 items\n",
      "processed 6900/58\n",
      "reading directory Paras with 79 items\n",
      "processed 7000/79\n",
      "reading directory Parasect with 60 items\n",
      "reading directory Persian with 62 items\n",
      "processed 7100/62\n",
      "reading directory Pidgeot with 98 items\n",
      "processed 7200/98\n",
      "reading directory Pidgeotto with 69 items\n",
      "processed 7300/69\n",
      "reading directory Pidgey with 79 items\n",
      "reading directory Pikachu with 93 items\n",
      "processed 7400/93\n",
      "reading directory Pinsir with 69 items\n",
      "processed 7500/69\n",
      "reading directory Poliwag with 99 items\n",
      "processed 7600/99\n",
      "reading directory Poliwhirl with 95 items\n",
      "processed 7700/95\n",
      "reading directory Poliwrath with 86 items\n",
      "processed 7800/86\n",
      "reading directory Ponyta with 99 items\n",
      "processed 7900/99\n",
      "reading directory Porygon with 56 items\n",
      "reading directory Primeape with 93 items\n",
      "processed 8000/93\n",
      "reading directory Psyduck with 112 items\n",
      "processed 8100/112\n",
      "reading directory Raichu with 76 items\n",
      "processed 8200/76\n",
      "reading directory Rapidash with 94 items\n",
      "processed 8300/94\n",
      "reading directory Raticate with 63 items\n",
      "processed 8400/63\n",
      "reading directory Rattata with 37 items\n",
      "reading directory Rhydon with 65 items\n",
      "processed 8500/65\n",
      "reading directory Rhyhorn with 60 items\n",
      "reading directory Sandshrew with 58 items\n",
      "processed 8600/58\n",
      "reading directory Sandslash with 81 items\n",
      "processed 8700/81\n",
      "reading directory Scyther with 72 items\n",
      "processed 8800/72\n",
      "reading directory Seadra with 63 items\n",
      "reading directory Seaking with 68 items\n",
      "processed 8900/68\n",
      "reading directory Seel with 72 items\n",
      "processed 9000/72\n",
      "reading directory Shellder with 77 items\n",
      "reading directory Slowbro with 68 items\n",
      "processed 9100/68\n",
      "reading directory Slowpoke with 59 items\n",
      "processed 9200/59\n",
      "reading directory Snorlax with 76 items\n",
      "reading directory Spearow with 48 items\n",
      "processed 9300/48\n",
      "reading directory Squirtle with 54 items\n",
      "reading directory Starmie with 55 items\n",
      "processed 9400/55\n",
      "reading directory Staryu with 58 items\n",
      "processed 9500/58\n",
      "reading directory Tangela with 69 items\n",
      "reading directory Tauros with 54 items\n",
      "processed 9600/54\n",
      "reading directory Tentacool with 78 items\n",
      "processed 9700/78\n",
      "reading directory Tentacruel with 63 items\n",
      "reading directory Vaporeon with 95 items\n",
      "processed 9800/95\n",
      "reading directory Venomoth with 54 items\n",
      "processed 9900/54\n",
      "reading directory Venonat with 77 items\n",
      "reading directory Venusaur with 47 items\n",
      "processed 10000/47\n",
      "reading directory Victreebel with 85 items\n",
      "processed 10100/85\n",
      "reading directory Vileplume with 65 items\n",
      "reading directory Voltorb with 90 items\n",
      "processed 10200/90\n",
      "reading directory Vulpix with 62 items\n",
      "processed 10300/62\n",
      "reading directory Wartortle with 77 items\n",
      "processed 10400/77\n",
      "reading directory Weedle with 39 items\n",
      "reading directory Weepinbell with 76 items\n",
      "processed 10500/76\n",
      "reading directory Weezing with 65 items\n",
      "reading directory Wigglytuff with 89 items\n",
      "processed 10600/89\n",
      "reading directory Zapdos with 78 items\n",
      "processed 10700/78\n",
      "reading directory Zubat with 54 items\n",
      "processed 10800/54\n",
      "processed 10818 items\n",
      "label statistics: [ 64.  63.  96.  82.  60.  72.  43.  60.  52.  45.  68.  59.  76.  80.\n",
      " 100.  40.  72.  54.  63.  72.  60.  81.  51.  62.  78.  81.  72.  64.\n",
      "  59.  71.  92.  39.  65.  81.  55.  61.  64.  72.  79.  93. 121.  78.\n",
      "  90.  81.  81.  71.  80.  62.  84. 100. 121.  67.  63.  65.  73.  72.\n",
      "  80.  69.  79.  76.  70.  63.  97.  54.  65.  63.  69.  77.  74.  85.\n",
      "  61.  57.  72.  76.  67.  67.  58.  92.  60.  76.  74.  64.  90.  74.\n",
      "  61.  88.  96.  81.  60.  76.  76.  86.  63.  60.  65.  59.  58.  79.\n",
      "  60.  62.  98.  69.  79.  93.  69.  99.  95.  86.  99.  56.  93. 112.\n",
      "  76.  94.  63.  37.  65.  60.  58.  81.  72.  63.  68.  72.  77.  68.\n",
      "  59.  76.  48.  54.  55.  58.  69.  54.  78.  63.  95.  54.  77.  47.\n",
      "  85.  65.  90.  62.  77.  39.  76.  65.  89.  78.  54.] summing to 10818.0\n",
      "finished feature import\n",
      "data shape: (64, 64, 3)\n",
      "found 1127 items!\n",
      "x dim: (1127, 64, 64, 3)\n",
      "reading directory Abra with 7 items\n",
      "reading directory Aerodactyl with 6 items\n",
      "reading directory Alakazam with 10 items\n",
      "reading directory Arbok with 9 items\n",
      "reading directory Arcanine with 6 items\n",
      "reading directory Articuno with 7 items\n",
      "reading directory Beedrill with 4 items\n",
      "reading directory Bellsprout with 6 items\n",
      "reading directory Blastoise with 5 items\n",
      "reading directory Bulbasaur with 5 items\n",
      "reading directory Butterfree with 7 items\n",
      "reading directory Caterpie with 6 items\n",
      "reading directory Chansey with 8 items\n",
      "reading directory Charizard with 8 items\n",
      "reading directory Charmander with 11 items\n",
      "processed 100/11\n",
      "reading directory Charmeleon with 4 items\n",
      "reading directory Clefable with 8 items\n",
      "reading directory Clefairy with 6 items\n",
      "reading directory Cloyster with 7 items\n",
      "reading directory Cubone with 7 items\n",
      "reading directory Dewgong with 6 items\n",
      "reading directory Diglett with 9 items\n",
      "reading directory Ditto with 5 items\n",
      "reading directory Dodrio with 6 items\n",
      "reading directory Doduo with 8 items\n",
      "reading directory Dragonair with 8 items\n",
      "reading directory Dragonite with 8 items\n",
      "reading directory Dratini with 7 items\n",
      "reading directory Drowzee with 6 items\n",
      "processed 200/6\n",
      "reading directory Dugtrio with 7 items\n",
      "reading directory Eevee with 10 items\n",
      "reading directory Ekans with 4 items\n",
      "reading directory Electabuzz with 7 items\n",
      "reading directory Electrode with 9 items\n",
      "reading directory Exeggcute with 6 items\n",
      "reading directory Exeggutor with 6 items\n",
      "reading directory Farfetchd with 7 items\n",
      "reading directory Fearow with 8 items\n",
      "reading directory Flareon with 8 items\n",
      "reading directory Gastly with 10 items\n",
      "reading directory Gengar with 13 items\n",
      "reading directory Geodude with 8 items\n",
      "processed 300/8\n",
      "reading directory Gloom with 9 items\n",
      "reading directory Golbat with 9 items\n",
      "reading directory Goldeen with 8 items\n",
      "reading directory Golduck with 7 items\n",
      "reading directory Golem with 8 items\n",
      "reading directory Graveler with 6 items\n",
      "reading directory Grimer with 9 items\n",
      "reading directory Growlithe with 11 items\n",
      "reading directory Gyarados with 13 items\n",
      "reading directory Haunter with 7 items\n",
      "reading directory Hitmonchan with 6 items\n",
      "reading directory Hitmonlee with 7 items\n",
      "processed 400/7\n",
      "reading directory Horsea with 8 items\n",
      "reading directory Hypno with 8 items\n",
      "reading directory Ivysaur with 8 items\n",
      "reading directory Jigglypuff with 7 items\n",
      "reading directory Jolteon with 8 items\n",
      "reading directory Jynx with 8 items\n",
      "reading directory Kabuto with 7 items\n",
      "reading directory Kabutops with 7 items\n",
      "reading directory Kadabra with 10 items\n",
      "reading directory Kakuna with 6 items\n",
      "reading directory Kangaskhan with 7 items\n",
      "reading directory Kingler with 6 items\n",
      "reading directory Koffing with 7 items\n",
      "processed 500/7\n",
      "reading directory Krabby with 8 items\n",
      "reading directory Lapras with 8 items\n",
      "reading directory Lickitung with 9 items\n",
      "reading directory Machamp with 6 items\n",
      "reading directory Machoke with 6 items\n",
      "reading directory Machop with 7 items\n",
      "reading directory Magikarp with 8 items\n",
      "reading directory Magmar with 7 items\n",
      "reading directory Magnemite with 7 items\n",
      "reading directory Magneton with 6 items\n",
      "reading directory Mankey with 10 items\n",
      "reading directory Marowak with 6 items\n",
      "reading directory Meowth with 8 items\n",
      "reading directory Metapod with 8 items\n",
      "processed 600/8\n",
      "reading directory Mew with 7 items\n",
      "reading directory Mewtwo with 9 items\n",
      "reading directory Moltres with 8 items\n",
      "reading directory Mr.Mime with 6 items\n",
      "reading directory Muk with 9 items\n",
      "reading directory Nidoking with 10 items\n",
      "reading directory Nidoqueen with 9 items\n",
      "reading directory Nidoran-f with 6 items\n",
      "reading directory Nidoran-m with 8 items\n",
      "reading directory Nidorina with 8 items\n",
      "reading directory Nidorino with 9 items\n",
      "reading directory Ninetales with 6 items\n",
      "reading directory Oddish with 6 items\n",
      "processed 700/6\n",
      "reading directory Omanyte with 7 items\n",
      "reading directory Omastar with 6 items\n",
      "reading directory Onix with 6 items\n",
      "reading directory Paras with 8 items\n",
      "reading directory Parasect with 6 items\n",
      "reading directory Persian with 6 items\n",
      "reading directory Pidgeot with 10 items\n",
      "reading directory Pidgeotto with 7 items\n",
      "reading directory Pidgey with 8 items\n",
      "reading directory Pikachu with 10 items\n",
      "reading directory Pinsir with 7 items\n",
      "reading directory Poliwag with 10 items\n",
      "reading directory Poliwhirl with 10 items\n",
      "processed 800/10\n",
      "reading directory Poliwrath with 9 items\n",
      "reading directory Ponyta with 10 items\n",
      "reading directory Porygon with 6 items\n",
      "reading directory Primeape with 10 items\n",
      "reading directory Psyduck with 12 items\n",
      "reading directory Raichu with 8 items\n",
      "reading directory Rapidash with 10 items\n",
      "reading directory Raticate with 7 items\n",
      "reading directory Rattata with 4 items\n",
      "reading directory Rhydon with 7 items\n",
      "reading directory Rhyhorn with 6 items\n",
      "reading directory Sandshrew with 6 items\n",
      "processed 900/6\n",
      "reading directory Sandslash with 9 items\n",
      "reading directory Scyther with 7 items\n",
      "reading directory Seadra with 7 items\n",
      "reading directory Seaking with 7 items\n",
      "reading directory Seel with 8 items\n",
      "reading directory Shellder with 8 items\n",
      "reading directory Slowbro with 7 items\n",
      "reading directory Slowpoke with 6 items\n",
      "reading directory Snorlax with 8 items\n",
      "reading directory Spearow with 5 items\n",
      "reading directory Squirtle with 5 items\n",
      "reading directory Starmie with 6 items\n",
      "reading directory Staryu with 6 items\n",
      "reading directory Tangela with 7 items\n",
      "reading directory Tauros with 6 items\n",
      "processed 1000/6\n",
      "reading directory Tentacool with 8 items\n",
      "reading directory Tentacruel with 6 items\n",
      "reading directory Vaporeon with 10 items\n",
      "reading directory Venomoth with 5 items\n",
      "reading directory Venonat with 8 items\n",
      "reading directory Venusaur with 5 items\n",
      "reading directory Victreebel with 9 items\n",
      "reading directory Vileplume with 7 items\n",
      "reading directory Voltorb with 10 items\n",
      "reading directory Vulpix with 6 items\n",
      "reading directory Wartortle with 8 items\n",
      "reading directory Weedle with 4 items\n",
      "reading directory Weepinbell with 8 items\n",
      "reading directory Weezing with 7 items\n",
      "processed 1100/7\n",
      "reading directory Wigglytuff with 9 items\n",
      "reading directory Zapdos with 8 items\n",
      "reading directory Zubat with 6 items\n",
      "processed 1127 items\n",
      "label statistics: [ 7.  6. 10.  9.  6.  7.  4.  6.  5.  5.  7.  6.  8.  8. 11.  4.  8.  6.\n",
      "  7.  7.  6.  9.  5.  6.  8.  8.  8.  7.  6.  7. 10.  4.  7.  9.  6.  6.\n",
      "  7.  8.  8. 10. 13.  8.  9.  9.  8.  7.  8.  6.  9. 11. 13.  7.  6.  7.\n",
      "  8.  8.  8.  7.  8.  8.  7.  7. 10.  6.  7.  6.  7.  8.  8.  9.  6.  6.\n",
      "  7.  8.  7.  7.  6. 10.  6.  8.  8.  7.  9.  8.  6.  9. 10.  9.  6.  8.\n",
      "  8.  9.  6.  6.  7.  6.  6.  8.  6.  6. 10.  7.  8. 10.  7. 10. 10.  9.\n",
      " 10.  6. 10. 12.  8. 10.  7.  4.  7.  6.  6.  9.  7.  7.  7.  8.  8.  7.\n",
      "  6.  8.  5.  5.  6.  6.  7.  6.  8.  6. 10.  5.  8.  5.  9.  7. 10.  6.\n",
      "  8.  4.  8.  7.  9.  8.  6.] summing to 1127.0\n",
      "finished feature import\n",
      "X train shape: torch.Size([10818, 3, 64, 64])\n",
      "Y Shape: torch.Size([10818])\n",
      "indim: (3, 64, 64) outdim: (151,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RUNNER\n",
    "\"\"\"\n",
    "\n",
    "# directory containing original images\n",
    "raw_data_dir = '../../Data/pokemon/PokemonData'\n",
    "test_data_dir = '../../Data/pokemon/PokemonTestData'\n",
    "\n",
    "# directory to save processed numpy arrays\n",
    "processed_data_dir = '../../Data/pokemon/PokemonDataProcessed'\n",
    "processed_test_dir = '../../Data/pokemon/PokemonTestProcessed'\n",
    "\n",
    "augmentation_data_dir = '../../Data/pokemon/PokemonDataAugmented'\n",
    "augmentation_data_dir_relative = '../../PokemonDataAugmented'\n",
    "processed_augmentation_data_dir = '../../Data/pokemon/PokemonDataProcessedAugmented'\n",
    "\n",
    "# specifies which categories to read from. Leave as None to read from all\n",
    "folders = None\n",
    "\n",
    "##############################################################################################\n",
    "# \n",
    "# CREATING TEST SET\n",
    "#\n",
    "#\n",
    "# WARNING: EXECUTE THE BELOW FUNCTION ONCE!!!! IT PERMANENTLY SPLICES YOUR DATA!\n",
    "#\n",
    "###############################################################################################\n",
    "#create_test_folder(raw_data_dir, test_data_dir)\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "#\n",
    "# PREPROCESSING STEPS\n",
    "#\n",
    "###############################################################################################\n",
    "#preprocess(raw_data_dir, processed_data_dir, 64, True, augmentation_data_dir, processed_augmentation_data_dir, augmentation_data_dir_relative)\n",
    "#preprocess(test_data_dir, processed_test_dir, 64)\n",
    "\n",
    "\n",
    "x_train, y_train = import_images(processed_data_dir, folders)\n",
    "x_test, y_test = import_images(processed_test_dir, folders)\n",
    "x_train = np.moveaxis(x_train, -1, 1)\n",
    "x_test = np.moveaxis(x_test, -1, 1)\n",
    "\n",
    "in_dim = x_train[0].shape\n",
    "num_classes = y_train[0].shape\n",
    "\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "x_train = torch.from_numpy(x_train)\n",
    "#x_train = torch.unsqueeze(x_train, 2)\n",
    "x_train = x_train.type(torch.float32).to(device)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "#y_train = torch.unsqueeze(y_train, 1)\n",
    "y_train = y_train.type(torch.LongTensor).to(device)\n",
    "\n",
    "x_test = torch.from_numpy(x_test)\n",
    "#x_test = torch.unsqueeze(x_test, 2)\n",
    "x_test = x_test.type(torch.float32).to(device)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "#y_test = torch.unsqueeze(y_test, 1)\n",
    "y_test = y_test.type(torch.LongTensor).to(device)\n",
    "\n",
    "\n",
    "\n",
    "print(f'X train shape: {x_train.shape}\\nY Shape: {y_train.shape}')\n",
    "print(f'indim: {in_dim} outdim: {num_classes}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first implemented a simple 2 layer CNN. My accuracy was 0.538."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer2_dim_h 29.0\n",
      "layer2_dim_w 29.0\n",
      "epoch 0\n",
      "training\n",
      "\tTraining epoch 0 Accuracy: 16.8330560177482%\n",
      "testing\n",
      "\ttesting accuracy: 31.854480922803905%\n",
      "epoch 1\n",
      "training\n",
      "\tTraining epoch 1 Accuracy: 53.253836198927715%\n",
      "testing\n",
      "\ttesting accuracy: 43.47826086956522%\n",
      "epoch 2\n",
      "training\n",
      "\tTraining epoch 2 Accuracy: 74.5146977260122%\n",
      "testing\n",
      "\ttesting accuracy: 48.535936113575865%\n",
      "epoch 3\n",
      "training\n",
      "\tTraining epoch 3 Accuracy: 87.13255684969495%\n",
      "testing\n",
      "\ttesting accuracy: 51.90771960958296%\n",
      "epoch 4\n",
      "training\n",
      "\tTraining epoch 4 Accuracy: 94.88814938066186%\n",
      "testing\n",
      "\ttesting accuracy: 51.109139307897074%\n",
      "epoch 5\n",
      "training\n",
      "\tTraining epoch 5 Accuracy: 98.09576631540025%\n",
      "testing\n",
      "\ttesting accuracy: 52.70629991126886%\n",
      "epoch 6\n",
      "training\n",
      "\tTraining epoch 6 Accuracy: 99.48234424107969%\n",
      "testing\n",
      "\ttesting accuracy: 53.59361135758651%\n",
      "epoch 7\n",
      "training\n",
      "\tTraining epoch 7 Accuracy: 99.85209835459419%\n",
      "testing\n",
      "\ttesting accuracy: 53.06122448979592%\n",
      "epoch 8\n",
      "training\n",
      "\tTraining epoch 8 Accuracy: 99.94453688297283%\n",
      "testing\n",
      "\ttesting accuracy: 53.85980479148181%\n",
      "epoch 9\n",
      "training\n",
      "\tTraining epoch 9 Accuracy: 99.9722684414864%\n",
      "testing\n",
      "\ttesting accuracy: 53.85980479148181%\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00005\n",
    "criterion = nn.NLLLoss()\n",
    "momentum = 0.9\n",
    "cnn = CNN(in_dim, num_classes[0]).to(device)\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "train_batch_size = 50\n",
    "test_batch_size = 10\n",
    "\n",
    "# Create Dataset objects, then create torch dataloader\n",
    "train_dataset = SimpleDataset(x_train, y_train)\n",
    "test_dataset = SimpleDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "def train(net, loader, optimizer, epoch, device):\n",
    "    print(f'training')\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # clear up gradients for backprop\n",
    "        optimizer.zero_grad()\n",
    "        output = F.log_softmax(net(data), dim=1)\n",
    "        #print(f'output: {output} target: {target}')\n",
    "        # use NLL loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradients and make updates\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += (pred.eq(target.data.view_as(pred)).sum().item())\n",
    "\n",
    "    print(f'\\tTraining epoch {epoch} Accuracy: {100 * correct / len(loader.dataset)}%')\n",
    "\n",
    "\n",
    "def test(net, loader, device):\n",
    "    print(f'testing')\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = net(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += (pred.eq(target.data.view_as(pred)).sum().item())\n",
    "\n",
    "            total = total + 1\n",
    "    accuracy = 100 * correct / len(loader.dataset)\n",
    "    print(f'\\ttesting accuracy: {accuracy}%')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "n_epoch = 10\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print(f'epoch {epoch}')\n",
    "    train(cnn, train_loader, optimizer, epoch, device)\n",
    "    test(cnn, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then implemented the VGG16 architecture, and acheived an accuracy of 0.62, which is a significant improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training\n",
      "\tTraining epoch 0 Accuracy: 2.089110741356998%\n",
      "testing\n",
      "\ttesting accuracy: 3.1055900621118013%\n",
      "epoch 1\n",
      "training\n",
      "\tTraining epoch 1 Accuracy: 3.01349602514328%\n",
      "testing\n",
      "\ttesting accuracy: 5.146406388642413%\n",
      "epoch 2\n",
      "training\n",
      "\tTraining epoch 2 Accuracy: 5.592530966907007%\n",
      "testing\n",
      "\ttesting accuracy: 8.16326530612245%\n",
      "epoch 3\n",
      "training\n",
      "\tTraining epoch 3 Accuracy: 8.310223701238677%\n",
      "testing\n",
      "\ttesting accuracy: 7.187222715173026%\n",
      "epoch 4\n",
      "training\n",
      "\tTraining epoch 4 Accuracy: 10.45479755962285%\n",
      "testing\n",
      "\ttesting accuracy: 12.156166814551908%\n",
      "epoch 5\n",
      "training\n",
      "\tTraining epoch 5 Accuracy: 12.987613237197264%\n",
      "testing\n",
      "\ttesting accuracy: 13.57586512866016%\n",
      "epoch 6\n",
      "training\n",
      "\tTraining epoch 6 Accuracy: 16.056572379367722%\n",
      "testing\n",
      "\ttesting accuracy: 18.189884649511978%\n",
      "epoch 7\n",
      "training\n",
      "\tTraining epoch 7 Accuracy: 18.654095026807173%\n",
      "testing\n",
      "\ttesting accuracy: 21.56166814551908%\n",
      "epoch 8\n",
      "training\n",
      "\tTraining epoch 8 Accuracy: 20.93732667775929%\n",
      "testing\n",
      "\ttesting accuracy: 23.77994676131322%\n",
      "epoch 9\n",
      "training\n",
      "\tTraining epoch 9 Accuracy: 24.60713625439083%\n",
      "testing\n",
      "\ttesting accuracy: 27.32919254658385%\n",
      "epoch 10\n",
      "training\n",
      "\tTraining epoch 10 Accuracy: 26.54834535034202%\n",
      "testing\n",
      "\ttesting accuracy: 28.039041703637977%\n",
      "epoch 11\n",
      "training\n",
      "\tTraining epoch 11 Accuracy: 29.247550378997968%\n",
      "testing\n",
      "\ttesting accuracy: 31.677018633540374%\n",
      "epoch 12\n",
      "training\n",
      "\tTraining epoch 12 Accuracy: 32.17785172860048%\n",
      "testing\n",
      "\ttesting accuracy: 31.410825199645075%\n",
      "epoch 13\n",
      "training\n",
      "\tTraining epoch 13 Accuracy: 35.42244407469033%\n",
      "testing\n",
      "\ttesting accuracy: 37.53327417923691%\n",
      "epoch 14\n",
      "training\n",
      "\tTraining epoch 14 Accuracy: 37.75189498983176%\n",
      "testing\n",
      "\ttesting accuracy: 39.57409050576752%\n",
      "epoch 15\n",
      "training\n",
      "\tTraining epoch 15 Accuracy: 40.58975781105565%\n",
      "testing\n",
      "\ttesting accuracy: 38.952972493345165%\n",
      "epoch 16\n",
      "training\n",
      "\tTraining epoch 16 Accuracy: 43.02089110741357%\n",
      "testing\n",
      "\ttesting accuracy: 38.68677905944987%\n",
      "epoch 17\n",
      "training\n",
      "\tTraining epoch 17 Accuracy: 45.61841375485302%\n",
      "testing\n",
      "\ttesting accuracy: 42.67968056787932%\n",
      "epoch 18\n",
      "training\n",
      "\tTraining epoch 18 Accuracy: 48.5579589572934%\n",
      "testing\n",
      "\ttesting accuracy: 47.11623779946761%\n",
      "epoch 19\n",
      "training\n",
      "\tTraining epoch 19 Accuracy: 51.793307450545385%\n",
      "testing\n",
      "\ttesting accuracy: 44.89795918367347%\n",
      "epoch 20\n",
      "training\n",
      "\tTraining epoch 20 Accuracy: 54.48326862636347%\n",
      "testing\n",
      "\ttesting accuracy: 48.358473824312334%\n",
      "epoch 21\n",
      "training\n",
      "\tTraining epoch 21 Accuracy: 56.22111295988168%\n",
      "testing\n",
      "\ttesting accuracy: 49.77817213842059%\n",
      "epoch 22\n",
      "training\n",
      "\tTraining epoch 22 Accuracy: 58.254760584211496%\n",
      "testing\n",
      "\ttesting accuracy: 49.68944099378882%\n",
      "epoch 23\n",
      "training\n",
      "\tTraining epoch 23 Accuracy: 60.86152708448881%\n",
      "testing\n",
      "\ttesting accuracy: 51.02040816326531%\n",
      "epoch 24\n",
      "training\n",
      "\tTraining epoch 24 Accuracy: 62.91366241449436%\n",
      "testing\n",
      "\ttesting accuracy: 53.41614906832298%\n",
      "epoch 25\n",
      "training\n",
      "\tTraining epoch 25 Accuracy: 65.10445553706785%\n",
      "testing\n",
      "\ttesting accuracy: 52.88376220053239%\n",
      "epoch 26\n",
      "training\n",
      "\tTraining epoch 26 Accuracy: 66.83305601774819%\n",
      "testing\n",
      "\ttesting accuracy: 53.94853593611358%\n",
      "epoch 27\n",
      "training\n",
      "\tTraining epoch 27 Accuracy: 69.5692364577556%\n",
      "testing\n",
      "\ttesting accuracy: 54.74711623779947%\n",
      "epoch 28\n",
      "training\n",
      "\tTraining epoch 28 Accuracy: 70.38269550748753%\n",
      "testing\n",
      "\ttesting accuracy: 56.078083407275955%\n",
      "epoch 29\n",
      "training\n",
      "\tTraining epoch 29 Accuracy: 72.19449066370863%\n",
      "testing\n",
      "\ttesting accuracy: 56.16681455190772%\n",
      "epoch 30\n",
      "training\n",
      "\tTraining epoch 30 Accuracy: 73.3961915326308%\n",
      "testing\n",
      "\ttesting accuracy: 55.81188997338066%\n",
      "epoch 31\n",
      "training\n",
      "\tTraining epoch 31 Accuracy: 75.25420595304122%\n",
      "testing\n",
      "\ttesting accuracy: 54.83584738243123%\n",
      "epoch 32\n",
      "training\n",
      "\tTraining epoch 32 Accuracy: 76.12312811980033%\n",
      "testing\n",
      "\ttesting accuracy: 55.81188997338066%\n",
      "epoch 33\n",
      "training\n",
      "\tTraining epoch 33 Accuracy: 78.67443150305047%\n",
      "testing\n",
      "\ttesting accuracy: 58.74001774622893%\n",
      "epoch 34\n",
      "training\n",
      "\tTraining epoch 34 Accuracy: 79.25679423183583%\n",
      "testing\n",
      "\ttesting accuracy: 55.63442768411713%\n",
      "epoch 35\n",
      "training\n",
      "\tTraining epoch 35 Accuracy: 80.90220003697542%\n",
      "testing\n",
      "\ttesting accuracy: 58.473824312333626%\n",
      "epoch 36\n",
      "training\n",
      "\tTraining epoch 36 Accuracy: 81.90977999630246%\n",
      "testing\n",
      "\ttesting accuracy: 56.255545696539485%\n",
      "epoch 37\n",
      "training\n",
      "\tTraining epoch 37 Accuracy: 82.17785172860049%\n",
      "testing\n",
      "\ttesting accuracy: 59.62732919254658%\n",
      "epoch 38\n",
      "training\n",
      "\tTraining epoch 38 Accuracy: 83.3425771861712%\n",
      "testing\n",
      "\ttesting accuracy: 59.09494232475599%\n",
      "epoch 39\n",
      "training\n",
      "\tTraining epoch 39 Accuracy: 83.57367350711776%\n",
      "testing\n",
      "\ttesting accuracy: 60.15971606033718%\n",
      "epoch 40\n",
      "training\n",
      "\tTraining epoch 40 Accuracy: 84.86781290441856%\n",
      "testing\n",
      "\ttesting accuracy: 59.62732919254658%\n",
      "epoch 41\n",
      "training\n",
      "\tTraining epoch 41 Accuracy: 84.24847476428175%\n",
      "testing\n",
      "\ttesting accuracy: 54.56965394853594%\n",
      "epoch 42\n",
      "training\n",
      "\tTraining epoch 42 Accuracy: 86.21741541874654%\n",
      "testing\n",
      "\ttesting accuracy: 59.183673469387756%\n",
      "epoch 43\n",
      "training\n",
      "\tTraining epoch 43 Accuracy: 86.72582732482898%\n",
      "testing\n",
      "\ttesting accuracy: 59.36113575865129%\n",
      "epoch 44\n",
      "training\n",
      "\tTraining epoch 44 Accuracy: 87.24348308374931%\n",
      "testing\n",
      "\ttesting accuracy: 57.05412599822538%\n",
      "epoch 45\n",
      "training\n",
      "\tTraining epoch 45 Accuracy: 88.23257533740063%\n",
      "testing\n",
      "\ttesting accuracy: 60.692102928127774%\n",
      "epoch 46\n",
      "training\n",
      "\tTraining epoch 46 Accuracy: 88.58384174523941%\n",
      "testing\n",
      "\ttesting accuracy: 59.89352262644188%\n",
      "epoch 47\n",
      "training\n",
      "\tTraining epoch 47 Accuracy: 88.76871880199667%\n",
      "testing\n",
      "\ttesting accuracy: 58.74001774622893%\n",
      "epoch 48\n",
      "training\n",
      "\tTraining epoch 48 Accuracy: 89.04603438713255%\n",
      "testing\n",
      "\ttesting accuracy: 59.53859804791482%\n",
      "epoch 49\n",
      "training\n",
      "\tTraining epoch 49 Accuracy: 89.73007949713441%\n",
      "testing\n",
      "\ttesting accuracy: 62.28926353149956%\n",
      "epoch 50\n",
      "training\n",
      "\tTraining epoch 50 Accuracy: 89.54520244037715%\n",
      "testing\n",
      "\ttesting accuracy: 60.15971606033718%\n",
      "epoch 51\n",
      "training\n",
      "\tTraining epoch 51 Accuracy: 90.81161027916436%\n",
      "testing\n",
      "\ttesting accuracy: 61.1357586512866%\n",
      "epoch 52\n",
      "training\n",
      "\tTraining epoch 52 Accuracy: 90.2015159918654%\n",
      "testing\n",
      "\ttesting accuracy: 60.78083407275954%\n",
      "epoch 53\n",
      "training\n",
      "\tTraining epoch 53 Accuracy: 90.91329266038085%\n",
      "testing\n",
      "\ttesting accuracy: 60.60337178349601%\n",
      "epoch 54\n",
      "training\n",
      "\tTraining epoch 54 Accuracy: 91.22758365686818%\n",
      "testing\n",
      "\ttesting accuracy: 60.24844720496895%\n",
      "epoch 55\n",
      "training\n",
      "\tTraining epoch 55 Accuracy: 91.75448326862636%\n",
      "testing\n",
      "\ttesting accuracy: 56.78793256433008%\n",
      "epoch 56\n",
      "training\n",
      "\tTraining epoch 56 Accuracy: 91.47716768349048%\n",
      "testing\n",
      "\ttesting accuracy: 58.296362023070095%\n",
      "epoch 57\n",
      "training\n",
      "\tTraining epoch 57 Accuracy: 91.15363283416528%\n",
      "testing\n",
      "\ttesting accuracy: 62.55545696539485%\n",
      "epoch 58\n",
      "training\n",
      "\tTraining epoch 58 Accuracy: 92.40155296727676%\n",
      "testing\n",
      "\ttesting accuracy: 60.60337178349601%\n",
      "epoch 59\n",
      "training\n",
      "\tTraining epoch 59 Accuracy: 91.71750785727491%\n",
      "testing\n",
      "\ttesting accuracy: 62.99911268855368%\n",
      "epoch 60\n",
      "training\n",
      "\tTraining epoch 60 Accuracy: 92.7158439637641%\n",
      "testing\n",
      "\ttesting accuracy: 61.84560780834073%\n",
      "epoch 61\n",
      "training\n",
      "\tTraining epoch 61 Accuracy: 92.38306526160103%\n",
      "testing\n",
      "\ttesting accuracy: 56.96539485359361%\n",
      "epoch 62\n",
      "training\n",
      "\tTraining epoch 62 Accuracy: 93.02089110741358%\n",
      "testing\n",
      "\ttesting accuracy: 62.99911268855368%\n",
      "epoch 63\n",
      "training\n",
      "\tTraining epoch 63 Accuracy: 92.90072102052136%\n",
      "testing\n",
      "\ttesting accuracy: 60.33717834960071%\n",
      "epoch 64\n",
      "training\n",
      "\tTraining epoch 64 Accuracy: 93.23349972268441%\n",
      "testing\n",
      "\ttesting accuracy: 62.11180124223603%\n",
      "epoch 65\n",
      "training\n",
      "\tTraining epoch 65 Accuracy: 93.79737474579404%\n",
      "testing\n",
      "\ttesting accuracy: 62.46672582076309%\n",
      "epoch 66\n",
      "training\n",
      "\tTraining epoch 66 Accuracy: 92.77130708079127%\n",
      "testing\n",
      "\ttesting accuracy: 61.934338952972496%\n",
      "epoch 67\n",
      "training\n",
      "\tTraining epoch 67 Accuracy: 93.87132556849694%\n",
      "testing\n",
      "\ttesting accuracy: 61.66814551907719%\n",
      "epoch 68\n",
      "training\n",
      "\tTraining epoch 68 Accuracy: 93.39064522092808%\n",
      "testing\n",
      "\ttesting accuracy: 61.224489795918366%\n",
      "epoch 69\n",
      "training\n",
      "\tTraining epoch 69 Accuracy: 94.56461453133666%\n",
      "testing\n",
      "\ttesting accuracy: 61.756876663708965%\n",
      "epoch 70\n",
      "training\n",
      "\tTraining epoch 70 Accuracy: 94.76797929376964%\n",
      "testing\n",
      "\ttesting accuracy: 62.02307009760426%\n",
      "epoch 71\n",
      "training\n",
      "\tTraining epoch 71 Accuracy: 93.54779071917176%\n",
      "testing\n",
      "\ttesting accuracy: 61.4019520851819%\n",
      "epoch 72\n",
      "training\n",
      "\tTraining epoch 72 Accuracy: 93.63098539471251%\n",
      "testing\n",
      "\ttesting accuracy: 63.975155279503106%\n",
      "epoch 73\n",
      "training\n",
      "\tTraining epoch 73 Accuracy: 94.51839526714734%\n",
      "testing\n",
      "\ttesting accuracy: 60.869565217391305%\n",
      "epoch 74\n",
      "training\n",
      "\tTraining epoch 74 Accuracy: 94.51839526714734%\n",
      "testing\n",
      "\ttesting accuracy: 60.07098491570541%\n",
      "epoch 75\n",
      "training\n",
      "\tTraining epoch 75 Accuracy: 94.68478461822887%\n",
      "testing\n",
      "\ttesting accuracy: 62.99911268855368%\n",
      "epoch 76\n",
      "training\n",
      "\tTraining epoch 76 Accuracy: 94.49066370863376%\n",
      "testing\n",
      "\ttesting accuracy: 61.934338952972496%\n",
      "epoch 77\n",
      "training\n",
      "\tTraining epoch 77 Accuracy: 94.48141985579589%\n",
      "testing\n",
      "\ttesting accuracy: 61.224489795918366%\n",
      "epoch 78\n",
      "training\n",
      "\tTraining epoch 78 Accuracy: 94.878905527824%\n",
      "testing\n",
      "\ttesting accuracy: 59.36113575865129%\n",
      "epoch 79\n",
      "training\n",
      "\tTraining epoch 79 Accuracy: 94.74949158809392%\n",
      "testing\n",
      "\ttesting accuracy: 62.910381543921915%\n",
      "epoch 80\n",
      "training\n",
      "\tTraining epoch 80 Accuracy: 94.34276206322795%\n",
      "testing\n",
      "\ttesting accuracy: 61.047027506654835%\n",
      "epoch 81\n",
      "training\n",
      "\tTraining epoch 81 Accuracy: 94.49990756147162%\n",
      "testing\n",
      "\ttesting accuracy: 59.982253771073644%\n",
      "epoch 82\n",
      "training\n",
      "\tTraining epoch 82 Accuracy: 95.50748752079866%\n",
      "testing\n",
      "\ttesting accuracy: 61.756876663708965%\n",
      "epoch 83\n",
      "training\n",
      "\tTraining epoch 83 Accuracy: 94.90663708633758%\n",
      "testing\n",
      "\ttesting accuracy: 61.934338952972496%\n",
      "epoch 84\n",
      "training\n",
      "\tTraining epoch 84 Accuracy: 96.12682566093548%\n",
      "testing\n",
      "\ttesting accuracy: 61.57941437444543%\n",
      "epoch 85\n",
      "training\n",
      "\tTraining epoch 85 Accuracy: 96.44111665742281%\n",
      "testing\n",
      "\ttesting accuracy: 63.442768411712514%\n",
      "epoch 86\n",
      "training\n",
      "\tTraining epoch 86 Accuracy: 94.25956738768718%\n",
      "testing\n",
      "\ttesting accuracy: 60.78083407275954%\n",
      "epoch 87\n",
      "training\n",
      "\tTraining epoch 87 Accuracy: 95.78480310593456%\n",
      "testing\n",
      "\ttesting accuracy: 61.84560780834073%\n",
      "epoch 88\n",
      "training\n",
      "\tTraining epoch 88 Accuracy: 95.33185431687927%\n",
      "testing\n",
      "\ttesting accuracy: 61.756876663708965%\n",
      "epoch 89\n",
      "training\n",
      "\tTraining epoch 89 Accuracy: 95.73858384174524%\n",
      "testing\n",
      "\ttesting accuracy: 60.51464063886424%\n",
      "epoch 90\n",
      "training\n",
      "\tTraining epoch 90 Accuracy: 96.05287483823257%\n",
      "testing\n",
      "\ttesting accuracy: 61.66814551907719%\n",
      "epoch 91\n",
      "training\n",
      "\tTraining epoch 91 Accuracy: 95.4982436679608%\n",
      "testing\n",
      "\ttesting accuracy: 63.975155279503106%\n",
      "epoch 92\n",
      "training\n",
      "\tTraining epoch 92 Accuracy: 96.16380107228693%\n",
      "testing\n",
      "\ttesting accuracy: 63.620230700976045%\n",
      "epoch 93\n",
      "training\n",
      "\tTraining epoch 93 Accuracy: 95.47051210944721%\n",
      "testing\n",
      "\ttesting accuracy: 61.224489795918366%\n",
      "epoch 94\n",
      "training\n",
      "\tTraining epoch 94 Accuracy: 96.12682566093548%\n",
      "testing\n",
      "\ttesting accuracy: 60.95829636202307%\n",
      "epoch 95\n",
      "training\n",
      "\tTraining epoch 95 Accuracy: 96.61674986134221%\n",
      "testing\n",
      "\ttesting accuracy: 63.442768411712514%\n",
      "epoch 96\n",
      "training\n",
      "\tTraining epoch 96 Accuracy: 95.76631540025883%\n",
      "testing\n",
      "\ttesting accuracy: 63.53149955634428%\n",
      "epoch 97\n",
      "training\n",
      "\tTraining epoch 97 Accuracy: 94.97134405620262%\n",
      "testing\n",
      "\ttesting accuracy: 61.31322094055013%\n",
      "epoch 98\n",
      "training\n",
      "\tTraining epoch 98 Accuracy: 96.4688482159364%\n",
      "testing\n",
      "\ttesting accuracy: 62.20053238686779%\n",
      "epoch 99\n",
      "training\n",
      "\tTraining epoch 99 Accuracy: 96.3209465705306%\n",
      "testing\n",
      "\ttesting accuracy: 62.02307009760426%\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0005\n",
    "criterion = nn.NLLLoss()\n",
    "momentum = 0.9\n",
    "cnn = VGG16(in_dim, num_classes[0]).to(device)\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "train_batch_size = 50\n",
    "test_batch_size = 10\n",
    "\n",
    "# Create Dataset objects, then create torch dataloader\n",
    "train_dataset = SimpleDataset(x_train, y_train)\n",
    "test_dataset = SimpleDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "def train(net, loader, optimizer, epoch, device):\n",
    "    print(f'training')\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # clear up gradients for backprop\n",
    "        optimizer.zero_grad()\n",
    "        output = F.log_softmax(net(data), dim=1)\n",
    "        #print(f'output: {output} target: {target}')\n",
    "        # use NLL loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradients and make updates\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += (pred.eq(target.data.view_as(pred)).sum().item())\n",
    "\n",
    "    print(f'\\tTraining epoch {epoch} Accuracy: {100 * correct / len(loader.dataset)}%')\n",
    "\n",
    "\n",
    "def test(net, loader, device):\n",
    "    print(f'testing')\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = net(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += (pred.eq(target.data.view_as(pred)).sum().item())\n",
    "\n",
    "            total = total + 1\n",
    "    accuracy = 100 * correct / len(loader.dataset)\n",
    "    print(f'\\ttesting accuracy: {accuracy}%')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "n_epoch = 100\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print(f'epoch {epoch}')\n",
    "    train(cnn, train_loader, optimizer, epoch, device)\n",
    "    test(cnn, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation is used below, where augmented images are generated by random small rotaions, flipping and zooming. This doubles the training data. However, I wasn't able to get above a 0.3 accuracy with augmentation after trying various hyperparameters. The best model so far is the VGG16 without augmentation with an accuracy of 0.62, which is fairly good considering there are 151 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (64, 64, 3)\n",
      "found 21636 items!\n",
      "x dim: (21636, 64, 64, 3)\n",
      "reading directory Abra with 64 items\n",
      "reading directory Aerodactyl with 63 items\n",
      "processed 100/63\n",
      "reading directory Alakazam with 96 items\n",
      "processed 200/96\n",
      "reading directory Arbok with 82 items\n",
      "processed 300/82\n",
      "reading directory Arcanine with 60 items\n",
      "reading directory Articuno with 72 items\n",
      "processed 400/72\n",
      "reading directory Beedrill with 43 items\n",
      "reading directory Bellsprout with 60 items\n",
      "processed 500/60\n",
      "reading directory Blastoise with 52 items\n",
      "reading directory Bulbasaur with 45 items\n",
      "processed 600/45\n",
      "reading directory Butterfree with 68 items\n",
      "processed 700/68\n",
      "reading directory Caterpie with 59 items\n",
      "reading directory Chansey with 76 items\n",
      "processed 800/76\n",
      "reading directory Charizard with 80 items\n",
      "processed 900/80\n",
      "reading directory Charmander with 100 items\n",
      "processed 1000/100\n",
      "reading directory Charmeleon with 40 items\n",
      "reading directory Clefable with 72 items\n",
      "processed 1100/72\n",
      "reading directory Clefairy with 54 items\n",
      "reading directory Cloyster with 63 items\n",
      "processed 1200/63\n",
      "reading directory Cubone with 72 items\n",
      "processed 1300/72\n",
      "reading directory Dewgong with 60 items\n",
      "reading directory Diglett with 81 items\n",
      "processed 1400/81\n",
      "reading directory Ditto with 51 items\n",
      "processed 1500/51\n",
      "reading directory Dodrio with 62 items\n",
      "reading directory Doduo with 78 items\n",
      "processed 1600/78\n",
      "reading directory Dragonair with 81 items\n",
      "processed 1700/81\n",
      "reading directory Dragonite with 72 items\n",
      "processed 1800/72\n",
      "reading directory Dratini with 64 items\n",
      "reading directory Drowzee with 59 items\n",
      "processed 1900/59\n",
      "reading directory Dugtrio with 71 items\n",
      "processed 2000/71\n",
      "reading directory Eevee with 92 items\n",
      "reading directory Ekans with 39 items\n",
      "processed 2100/39\n",
      "reading directory Electabuzz with 65 items\n",
      "reading directory Electrode with 81 items\n",
      "processed 2200/81\n",
      "reading directory Exeggcute with 55 items\n",
      "processed 2300/55\n",
      "reading directory Exeggutor with 61 items\n",
      "reading directory Farfetchd with 64 items\n",
      "processed 2400/64\n",
      "reading directory Fearow with 72 items\n",
      "processed 2500/72\n",
      "reading directory Flareon with 79 items\n",
      "processed 2600/79\n",
      "reading directory Gastly with 93 items\n",
      "processed 2700/93\n",
      "reading directory Gengar with 121 items\n",
      "processed 2800/121\n",
      "reading directory Geodude with 78 items\n",
      "processed 2900/78\n",
      "reading directory Gloom with 90 items\n",
      "reading directory Golbat with 81 items\n",
      "processed 3000/81\n",
      "reading directory Goldeen with 81 items\n",
      "processed 3100/81\n",
      "reading directory Golduck with 71 items\n",
      "processed 3200/71\n",
      "reading directory Golem with 80 items\n",
      "processed 3300/80\n",
      "reading directory Graveler with 62 items\n",
      "reading directory Grimer with 84 items\n",
      "processed 3400/84\n",
      "reading directory Growlithe with 100 items\n",
      "processed 3500/100\n",
      "reading directory Gyarados with 121 items\n",
      "processed 3600/121\n",
      "reading directory Haunter with 67 items\n",
      "processed 3700/67\n",
      "reading directory Hitmonchan with 63 items\n",
      "processed 3800/63\n",
      "reading directory Hitmonlee with 65 items\n",
      "reading directory Horsea with 73 items\n",
      "processed 3900/73\n",
      "reading directory Hypno with 72 items\n",
      "processed 4000/72\n",
      "reading directory Ivysaur with 80 items\n",
      "reading directory Jigglypuff with 69 items\n",
      "processed 4100/69\n",
      "reading directory Jolteon with 79 items\n",
      "processed 4200/79\n",
      "reading directory Jynx with 76 items\n",
      "processed 4300/76\n",
      "reading directory Kabuto with 70 items\n",
      "reading directory Kabutops with 63 items\n",
      "processed 4400/63\n",
      "reading directory Kadabra with 97 items\n",
      "processed 4500/97\n",
      "reading directory Kakuna with 54 items\n",
      "reading directory Kangaskhan with 65 items\n",
      "processed 4600/65\n",
      "reading directory Kingler with 63 items\n",
      "processed 4700/63\n",
      "reading directory Koffing with 69 items\n",
      "reading directory Krabby with 77 items\n",
      "processed 4800/77\n",
      "reading directory Lapras with 74 items\n",
      "processed 4900/74\n",
      "reading directory Lickitung with 85 items\n",
      "processed 5000/85\n",
      "reading directory Machamp with 61 items\n",
      "reading directory Machoke with 57 items\n",
      "processed 5100/57\n",
      "reading directory Machop with 72 items\n",
      "processed 5200/72\n",
      "reading directory Magikarp with 76 items\n",
      "reading directory Magmar with 67 items\n",
      "processed 5300/67\n",
      "reading directory Magnemite with 67 items\n",
      "processed 5400/67\n",
      "reading directory Magneton with 58 items\n",
      "reading directory Mankey with 92 items\n",
      "processed 5500/92\n",
      "reading directory Marowak with 60 items\n",
      "processed 5600/60\n",
      "reading directory Meowth with 76 items\n",
      "processed 5700/76\n",
      "reading directory Metapod with 74 items\n",
      "reading directory Mew with 64 items\n",
      "processed 5800/64\n",
      "reading directory Mewtwo with 90 items\n",
      "processed 5900/90\n",
      "reading directory Moltres with 74 items\n",
      "processed 6000/74\n",
      "reading directory Mr.Mime with 61 items\n",
      "reading directory Muk with 88 items\n",
      "processed 6100/88\n",
      "reading directory Nidoking with 96 items\n",
      "processed 6200/96\n",
      "reading directory Nidoqueen with 81 items\n",
      "processed 6300/81\n",
      "reading directory Nidoran-f with 60 items\n",
      "processed 6400/60\n",
      "reading directory Nidoran-m with 76 items\n",
      "reading directory Nidorina with 76 items\n",
      "processed 6500/76\n",
      "reading directory Nidorino with 86 items\n",
      "processed 6600/86\n",
      "reading directory Ninetales with 63 items\n",
      "processed 6700/63\n",
      "reading directory Oddish with 60 items\n",
      "reading directory Omanyte with 65 items\n",
      "processed 6800/65\n",
      "reading directory Omastar with 59 items\n",
      "reading directory Onix with 58 items\n",
      "processed 6900/58\n",
      "reading directory Paras with 79 items\n",
      "processed 7000/79\n",
      "reading directory Parasect with 60 items\n",
      "reading directory Persian with 62 items\n",
      "processed 7100/62\n",
      "reading directory Pidgeot with 98 items\n",
      "processed 7200/98\n",
      "reading directory Pidgeotto with 69 items\n",
      "processed 7300/69\n",
      "reading directory Pidgey with 79 items\n",
      "reading directory Pikachu with 93 items\n",
      "processed 7400/93\n",
      "reading directory Pinsir with 69 items\n",
      "processed 7500/69\n",
      "reading directory Poliwag with 99 items\n",
      "processed 7600/99\n",
      "reading directory Poliwhirl with 95 items\n",
      "processed 7700/95\n",
      "reading directory Poliwrath with 86 items\n",
      "processed 7800/86\n",
      "reading directory Ponyta with 99 items\n",
      "processed 7900/99\n",
      "reading directory Porygon with 56 items\n",
      "reading directory Primeape with 93 items\n",
      "processed 8000/93\n",
      "reading directory Psyduck with 112 items\n",
      "processed 8100/112\n",
      "reading directory Raichu with 76 items\n",
      "processed 8200/76\n",
      "reading directory Rapidash with 94 items\n",
      "processed 8300/94\n",
      "reading directory Raticate with 63 items\n",
      "processed 8400/63\n",
      "reading directory Rattata with 37 items\n",
      "reading directory Rhydon with 65 items\n",
      "processed 8500/65\n",
      "reading directory Rhyhorn with 60 items\n",
      "reading directory Sandshrew with 58 items\n",
      "processed 8600/58\n",
      "reading directory Sandslash with 81 items\n",
      "processed 8700/81\n",
      "reading directory Scyther with 72 items\n",
      "processed 8800/72\n",
      "reading directory Seadra with 63 items\n",
      "reading directory Seaking with 68 items\n",
      "processed 8900/68\n",
      "reading directory Seel with 72 items\n",
      "processed 9000/72\n",
      "reading directory Shellder with 77 items\n",
      "reading directory Slowbro with 68 items\n",
      "processed 9100/68\n",
      "reading directory Slowpoke with 59 items\n",
      "processed 9200/59\n",
      "reading directory Snorlax with 76 items\n",
      "reading directory Spearow with 48 items\n",
      "processed 9300/48\n",
      "reading directory Squirtle with 54 items\n",
      "reading directory Starmie with 55 items\n",
      "processed 9400/55\n",
      "reading directory Staryu with 58 items\n",
      "processed 9500/58\n",
      "reading directory Tangela with 69 items\n",
      "reading directory Tauros with 54 items\n",
      "processed 9600/54\n",
      "reading directory Tentacool with 78 items\n",
      "processed 9700/78\n",
      "reading directory Tentacruel with 63 items\n",
      "reading directory Vaporeon with 95 items\n",
      "processed 9800/95\n",
      "reading directory Venomoth with 54 items\n",
      "processed 9900/54\n",
      "reading directory Venonat with 77 items\n",
      "reading directory Venusaur with 47 items\n",
      "processed 10000/47\n",
      "reading directory Victreebel with 85 items\n",
      "processed 10100/85\n",
      "reading directory Vileplume with 65 items\n",
      "reading directory Voltorb with 90 items\n",
      "processed 10200/90\n",
      "reading directory Vulpix with 62 items\n",
      "processed 10300/62\n",
      "reading directory Wartortle with 77 items\n",
      "processed 10400/77\n",
      "reading directory Weedle with 39 items\n",
      "reading directory Weepinbell with 76 items\n",
      "processed 10500/76\n",
      "reading directory Weezing with 65 items\n",
      "reading directory Wigglytuff with 89 items\n",
      "processed 10600/89\n",
      "reading directory Zapdos with 78 items\n",
      "processed 10700/78\n",
      "reading directory Zubat with 54 items\n",
      "processed 10800/54\n",
      "reading augmented directory Abra with 64 items\n",
      "reading augmented directory Aerodactyl with 63 items\n",
      "processed 10900/63\n",
      "reading augmented directory Alakazam with 96 items\n",
      "processed 11000/96\n",
      "reading augmented directory Arbok with 82 items\n",
      "processed 11100/82\n",
      "reading augmented directory Arcanine with 60 items\n",
      "reading augmented directory Articuno with 72 items\n",
      "processed 11200/72\n",
      "reading augmented directory Beedrill with 43 items\n",
      "reading augmented directory Bellsprout with 60 items\n",
      "processed 11300/60\n",
      "reading augmented directory Blastoise with 52 items\n",
      "processed 11400/52\n",
      "reading augmented directory Bulbasaur with 45 items\n",
      "reading augmented directory Butterfree with 68 items\n",
      "processed 11500/68\n",
      "reading augmented directory Caterpie with 59 items\n",
      "reading augmented directory Chansey with 76 items\n",
      "processed 11600/76\n",
      "reading augmented directory Charizard with 80 items\n",
      "processed 11700/80\n",
      "reading augmented directory Charmander with 100 items\n",
      "processed 11800/100\n",
      "reading augmented directory Charmeleon with 40 items\n",
      "reading augmented directory Clefable with 72 items\n",
      "processed 11900/72\n",
      "reading augmented directory Clefairy with 54 items\n",
      "processed 12000/54\n",
      "reading augmented directory Cloyster with 63 items\n",
      "reading augmented directory Cubone with 72 items\n",
      "processed 12100/72\n",
      "reading augmented directory Dewgong with 60 items\n",
      "reading augmented directory Diglett with 81 items\n",
      "processed 12200/81\n",
      "reading augmented directory Ditto with 51 items\n",
      "processed 12300/51\n",
      "reading augmented directory Dodrio with 62 items\n",
      "reading augmented directory Doduo with 78 items\n",
      "processed 12400/78\n",
      "reading augmented directory Dragonair with 81 items\n",
      "processed 12500/81\n",
      "reading augmented directory Dragonite with 72 items\n",
      "processed 12600/72\n",
      "reading augmented directory Dratini with 64 items\n",
      "reading augmented directory Drowzee with 59 items\n",
      "processed 12700/59\n",
      "reading augmented directory Dugtrio with 71 items\n",
      "processed 12800/71\n",
      "reading augmented directory Eevee with 92 items\n",
      "processed 12900/92\n",
      "reading augmented directory Ekans with 39 items\n",
      "reading augmented directory Electabuzz with 65 items\n",
      "processed 13000/65\n",
      "reading augmented directory Electrode with 81 items\n",
      "reading augmented directory Exeggcute with 55 items\n",
      "processed 13100/55\n",
      "reading augmented directory Exeggutor with 61 items\n",
      "processed 13200/61\n",
      "reading augmented directory Farfetchd with 64 items\n",
      "reading augmented directory Fearow with 72 items\n",
      "processed 13300/72\n",
      "reading augmented directory Flareon with 79 items\n",
      "processed 13400/79\n",
      "reading augmented directory Gastly with 93 items\n",
      "processed 13500/93\n",
      "reading augmented directory Gengar with 121 items\n",
      "processed 13600/121\n",
      "reading augmented directory Geodude with 78 items\n",
      "processed 13700/78\n",
      "reading augmented directory Gloom with 90 items\n",
      "processed 13800/90\n",
      "reading augmented directory Golbat with 81 items\n",
      "reading augmented directory Goldeen with 81 items\n",
      "processed 13900/81\n",
      "reading augmented directory Golduck with 71 items\n",
      "processed 14000/71\n",
      "reading augmented directory Golem with 80 items\n",
      "processed 14100/80\n",
      "reading augmented directory Graveler with 62 items\n",
      "reading augmented directory Grimer with 84 items\n",
      "processed 14200/84\n",
      "reading augmented directory Growlithe with 100 items\n",
      "processed 14300/100\n",
      "reading augmented directory Gyarados with 121 items\n",
      "processed 14400/121\n",
      "reading augmented directory Haunter with 67 items\n",
      "processed 14500/67\n",
      "reading augmented directory Hitmonchan with 63 items\n",
      "processed 14600/63\n",
      "reading augmented directory Hitmonlee with 65 items\n",
      "reading augmented directory Horsea with 73 items\n",
      "processed 14700/73\n",
      "reading augmented directory Hypno with 72 items\n",
      "processed 14800/72\n",
      "reading augmented directory Ivysaur with 80 items\n",
      "processed 14900/80\n",
      "reading augmented directory Jigglypuff with 69 items\n",
      "reading augmented directory Jolteon with 79 items\n",
      "processed 15000/79\n",
      "reading augmented directory Jynx with 76 items\n",
      "processed 15100/76\n",
      "reading augmented directory Kabuto with 70 items\n",
      "processed 15200/70\n",
      "reading augmented directory Kabutops with 63 items\n",
      "reading augmented directory Kadabra with 97 items\n",
      "processed 15300/97\n",
      "reading augmented directory Kakuna with 54 items\n",
      "processed 15400/54\n",
      "reading augmented directory Kangaskhan with 65 items\n",
      "reading augmented directory Kingler with 63 items\n",
      "processed 15500/63\n",
      "reading augmented directory Koffing with 69 items\n",
      "processed 15600/69\n",
      "reading augmented directory Krabby with 77 items\n",
      "reading augmented directory Lapras with 74 items\n",
      "processed 15700/74\n",
      "reading augmented directory Lickitung with 85 items\n",
      "processed 15800/85\n",
      "reading augmented directory Machamp with 61 items\n",
      "processed 15900/61\n",
      "reading augmented directory Machoke with 57 items\n",
      "reading augmented directory Machop with 72 items\n",
      "processed 16000/72\n",
      "reading augmented directory Magikarp with 76 items\n",
      "processed 16100/76\n",
      "reading augmented directory Magmar with 67 items\n",
      "reading augmented directory Magnemite with 67 items\n",
      "processed 16200/67\n",
      "reading augmented directory Magneton with 58 items\n",
      "processed 16300/58\n",
      "reading augmented directory Mankey with 92 items\n",
      "reading augmented directory Marowak with 60 items\n",
      "processed 16400/60\n",
      "reading augmented directory Meowth with 76 items\n",
      "processed 16500/76\n",
      "reading augmented directory Metapod with 74 items\n",
      "processed 16600/74\n",
      "reading augmented directory Mew with 64 items\n",
      "reading augmented directory Mewtwo with 90 items\n",
      "processed 16700/90\n",
      "reading augmented directory Moltres with 74 items\n",
      "processed 16800/74\n",
      "reading augmented directory Mr.Mime with 61 items\n",
      "reading augmented directory Muk with 88 items\n",
      "processed 16900/88\n",
      "reading augmented directory Nidoking with 96 items\n",
      "processed 17000/96\n",
      "reading augmented directory Nidoqueen with 81 items\n",
      "processed 17100/81\n",
      "reading augmented directory Nidoran-f with 60 items\n",
      "processed 17200/60\n",
      "reading augmented directory Nidoran-m with 76 items\n",
      "reading augmented directory Nidorina with 76 items\n",
      "processed 17300/76\n",
      "reading augmented directory Nidorino with 86 items\n",
      "processed 17400/86\n",
      "reading augmented directory Ninetales with 63 items\n",
      "processed 17500/63\n",
      "reading augmented directory Oddish with 60 items\n",
      "reading augmented directory Omanyte with 65 items\n",
      "processed 17600/65\n",
      "reading augmented directory Omastar with 59 items\n",
      "processed 17700/59\n",
      "reading augmented directory Onix with 58 items\n",
      "reading augmented directory Paras with 79 items\n",
      "processed 17800/79\n",
      "reading augmented directory Parasect with 60 items\n",
      "processed 17900/60\n",
      "reading augmented directory Persian with 62 items\n",
      "reading augmented directory Pidgeot with 98 items\n",
      "processed 18000/98\n",
      "reading augmented directory Pidgeotto with 69 items\n",
      "processed 18100/69\n",
      "reading augmented directory Pidgey with 79 items\n",
      "processed 18200/79\n",
      "reading augmented directory Pikachu with 93 items\n",
      "processed 18300/93\n",
      "reading augmented directory Pinsir with 69 items\n",
      "reading augmented directory Poliwag with 99 items\n",
      "processed 18400/99\n",
      "reading augmented directory Poliwhirl with 95 items\n",
      "processed 18500/95\n",
      "reading augmented directory Poliwrath with 86 items\n",
      "processed 18600/86\n",
      "reading augmented directory Ponyta with 99 items\n",
      "processed 18700/99\n",
      "reading augmented directory Porygon with 56 items\n",
      "processed 18800/56\n",
      "reading augmented directory Primeape with 93 items\n",
      "processed 18900/93\n",
      "reading augmented directory Psyduck with 112 items\n",
      "processed 19000/112\n",
      "reading augmented directory Raichu with 76 items\n",
      "reading augmented directory Rapidash with 94 items\n",
      "processed 19100/94\n",
      "reading augmented directory Raticate with 63 items\n",
      "processed 19200/63\n",
      "reading augmented directory Rattata with 37 items\n",
      "reading augmented directory Rhydon with 65 items\n",
      "processed 19300/65\n",
      "reading augmented directory Rhyhorn with 60 items\n",
      "processed 19400/60\n",
      "reading augmented directory Sandshrew with 58 items\n",
      "reading augmented directory Sandslash with 81 items\n",
      "processed 19500/81\n",
      "reading augmented directory Scyther with 72 items\n",
      "processed 19600/72\n",
      "reading augmented directory Seadra with 63 items\n",
      "reading augmented directory Seaking with 68 items\n",
      "processed 19700/68\n",
      "reading augmented directory Seel with 72 items\n",
      "processed 19800/72\n",
      "reading augmented directory Shellder with 77 items\n",
      "processed 19900/77\n",
      "reading augmented directory Slowbro with 68 items\n",
      "reading augmented directory Slowpoke with 59 items\n",
      "processed 20000/59\n",
      "reading augmented directory Snorlax with 76 items\n",
      "processed 20100/76\n",
      "reading augmented directory Spearow with 48 items\n",
      "reading augmented directory Squirtle with 54 items\n",
      "processed 20200/54\n",
      "reading augmented directory Starmie with 55 items\n",
      "reading augmented directory Staryu with 58 items\n",
      "processed 20300/58\n",
      "reading augmented directory Tangela with 69 items\n",
      "reading augmented directory Tauros with 54 items\n",
      "processed 20400/54\n",
      "reading augmented directory Tentacool with 78 items\n",
      "processed 20500/78\n",
      "reading augmented directory Tentacruel with 63 items\n",
      "reading augmented directory Vaporeon with 95 items\n",
      "processed 20600/95\n",
      "reading augmented directory Venomoth with 54 items\n",
      "processed 20700/54\n",
      "reading augmented directory Venonat with 77 items\n",
      "processed 20800/77\n",
      "reading augmented directory Venusaur with 47 items\n",
      "reading augmented directory Victreebel with 85 items\n",
      "processed 20900/85\n",
      "reading augmented directory Vileplume with 65 items\n",
      "processed 21000/65\n",
      "reading augmented directory Voltorb with 90 items\n",
      "reading augmented directory Vulpix with 62 items\n",
      "processed 21100/62\n",
      "reading augmented directory Wartortle with 77 items\n",
      "processed 21200/77\n",
      "reading augmented directory Weedle with 39 items\n",
      "reading augmented directory Weepinbell with 76 items\n",
      "processed 21300/76\n",
      "reading augmented directory Weezing with 65 items\n",
      "processed 21400/65\n",
      "reading augmented directory Wigglytuff with 89 items\n",
      "processed 21500/89\n",
      "reading augmented directory Zapdos with 78 items\n",
      "reading augmented directory Zubat with 54 items\n",
      "processed 21600/54\n",
      "processed 21636 items\n",
      "label statistics: [10882.    63.    96.    82.    60.    72.    43.    60.    52.    45.\n",
      "    68.    59.    76.    80.   100.    40.    72.    54.    63.    72.\n",
      "    60.    81.    51.    62.    78.    81.    72.    64.    59.    71.\n",
      "    92.    39.    65.    81.    55.    61.    64.    72.    79.    93.\n",
      "   121.    78.    90.    81.    81.    71.    80.    62.    84.   100.\n",
      "   121.    67.    63.    65.    73.    72.    80.    69.    79.    76.\n",
      "    70.    63.    97.    54.    65.    63.    69.    77.    74.    85.\n",
      "    61.    57.    72.    76.    67.    67.    58.    92.    60.    76.\n",
      "    74.    64.    90.    74.    61.    88.    96.    81.    60.    76.\n",
      "    76.    86.    63.    60.    65.    59.    58.    79.    60.    62.\n",
      "    98.    69.    79.    93.    69.    99.    95.    86.    99.    56.\n",
      "    93.   112.    76.    94.    63.    37.    65.    60.    58.    81.\n",
      "    72.    63.    68.    72.    77.    68.    59.    76.    48.    54.\n",
      "    55.    58.    69.    54.    78.    63.    95.    54.    77.    47.\n",
      "    85.    65.    90.    62.    77.    39.    76.    65.    89.    78.\n",
      "    54.] summing to 21636.0\n",
      "finished feature import\n",
      "X train shape: torch.Size([21636, 3, 64, 64])\n",
      "Y Shape: torch.Size([21636])\n",
      "indim: (3, 64, 64) outdim: (151,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"WITH AUGMENTATION\"\"\"\n",
    "\n",
    "x_train, y_train = import_images(processed_data_dir, folders, True, processed_augmentation_data_dir)\n",
    "x_train = np.moveaxis(x_train, -1, 1)\n",
    "\n",
    "in_dim = x_train[0].shape\n",
    "num_classes = y_train[0].shape\n",
    "\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "x_train = torch.from_numpy(x_train)\n",
    "#x_train = torch.unsqueeze(x_train, 2)\n",
    "x_train = x_train.type(torch.float32).to(device)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "#y_train = torch.unsqueeze(y_train, 1)\n",
    "y_train = y_train.type(torch.LongTensor).to(device)\n",
    "\n",
    "\n",
    "print(f'X train shape: {x_train.shape}\\nY Shape: {y_train.shape}')\n",
    "print(f'indim: {in_dim} outdim: {num_classes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "training\n",
      "\tTraining epoch 0 Accuracy: 49.681087077093736%\n",
      "testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eggyr\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttesting accuracy: 0.6211180124223602%\n",
      "epoch 1\n",
      "training\n",
      "\tTraining epoch 1 Accuracy: 50.29580329081161%\n",
      "testing\n",
      "\ttesting accuracy: 0.6211180124223602%\n",
      "epoch 2\n",
      "training\n",
      "\tTraining epoch 2 Accuracy: 50.29580329081161%\n",
      "testing\n",
      "\ttesting accuracy: 0.6211180124223602%\n",
      "epoch 3\n",
      "training\n",
      "\tTraining epoch 3 Accuracy: 50.29580329081161%\n",
      "testing\n",
      "\ttesting accuracy: 1.419698314108252%\n",
      "epoch 4\n",
      "training\n",
      "\tTraining epoch 4 Accuracy: 50.420595304122756%\n",
      "testing\n",
      "\ttesting accuracy: 3.460514640638864%\n",
      "epoch 5\n",
      "training\n",
      "\tTraining epoch 5 Accuracy: 51.941209095951194%\n",
      "testing\n",
      "\ttesting accuracy: 5.146406388642413%\n",
      "epoch 6\n",
      "training\n",
      "\tTraining epoch 6 Accuracy: 54.95470512109447%\n",
      "testing\n",
      "\ttesting accuracy: 14.729370008873115%\n",
      "epoch 7\n",
      "training\n",
      "\tTraining epoch 7 Accuracy: 57.875762617859124%\n",
      "testing\n",
      "\ttesting accuracy: 13.75332741792369%\n",
      "epoch 8\n",
      "training\n",
      "\tTraining epoch 8 Accuracy: 60.306895914217044%\n",
      "testing\n",
      "\ttesting accuracy: 12.244897959183673%\n",
      "epoch 9\n",
      "training\n",
      "\tTraining epoch 9 Accuracy: 63.40820854132002%\n",
      "testing\n",
      "\ttesting accuracy: 14.285714285714286%\n",
      "epoch 10\n",
      "training\n",
      "\tTraining epoch 10 Accuracy: 66.10741356997596%\n",
      "testing\n",
      "\ttesting accuracy: 23.513753327417923%\n",
      "epoch 11\n",
      "training\n",
      "\tTraining epoch 11 Accuracy: 69.22259197633574%\n",
      "testing\n",
      "\ttesting accuracy: 18.278615794143743%\n",
      "epoch 12\n",
      "training\n",
      "\tTraining epoch 12 Accuracy: 72.70752449621003%\n",
      "testing\n",
      "\ttesting accuracy: 23.247559893522627%\n",
      "epoch 13\n",
      "training\n",
      "\tTraining epoch 13 Accuracy: 76.4420410427066%\n",
      "testing\n",
      "\ttesting accuracy: 25.643300798580302%\n",
      "epoch 14\n",
      "training\n",
      "\tTraining epoch 14 Accuracy: 79.51562211129598%\n",
      "testing\n",
      "\ttesting accuracy: 23.77994676131322%\n",
      "epoch 15\n",
      "training\n",
      "\tTraining epoch 15 Accuracy: 83.00517655758921%\n",
      "testing\n",
      "\ttesting accuracy: 25.820763087843833%\n",
      "epoch 16\n",
      "training\n",
      "\tTraining epoch 16 Accuracy: 85.81068589388057%\n",
      "testing\n",
      "\ttesting accuracy: 23.513753327417923%\n",
      "epoch 17\n",
      "training\n",
      "\tTraining epoch 17 Accuracy: 89.1246071362544%\n",
      "testing\n",
      "\ttesting accuracy: 27.861579414374447%\n",
      "epoch 18\n",
      "training\n",
      "\tTraining epoch 18 Accuracy: 90.58513588463671%\n",
      "testing\n",
      "\ttesting accuracy: 27.861579414374447%\n",
      "epoch 19\n",
      "training\n",
      "\tTraining epoch 19 Accuracy: 92.75744130153448%\n",
      "testing\n",
      "\ttesting accuracy: 29.45874001774623%\n",
      "epoch 20\n",
      "training\n",
      "\tTraining epoch 20 Accuracy: 93.36753558883342%\n",
      "testing\n",
      "\ttesting accuracy: 29.103815439219165%\n",
      "epoch 21\n",
      "training\n",
      "\tTraining epoch 21 Accuracy: 95.03142909964873%\n",
      "testing\n",
      "\ttesting accuracy: 25.199645075421472%\n",
      "epoch 22\n",
      "training\n",
      "\tTraining epoch 22 Accuracy: 95.34572009613606%\n",
      "testing\n",
      "\ttesting accuracy: 31.94321206743567%\n",
      "epoch 23\n",
      "training\n",
      "\tTraining epoch 23 Accuracy: 96.3810316139767%\n",
      "testing\n",
      "\ttesting accuracy: 30.168589174800356%\n",
      "epoch 24\n",
      "training\n",
      "\tTraining epoch 24 Accuracy: 96.5566648178961%\n",
      "testing\n",
      "\ttesting accuracy: 29.103815439219165%\n",
      "epoch 25\n",
      "training\n",
      "\tTraining epoch 25 Accuracy: 96.95877241634314%\n",
      "testing\n",
      "\ttesting accuracy: 30.25732031943212%\n",
      "epoch 26\n",
      "training\n",
      "\tTraining epoch 26 Accuracy: 96.92641893141061%\n",
      "testing\n",
      "\ttesting accuracy: 29.19254658385093%\n",
      "epoch 27\n",
      "training\n",
      "\tTraining epoch 27 Accuracy: 97.2638195599926%\n",
      "testing\n",
      "\ttesting accuracy: 29.547471162377995%\n",
      "epoch 28\n",
      "training\n",
      "\tTraining epoch 28 Accuracy: 98.02643741911629%\n",
      "testing\n",
      "\ttesting accuracy: 28.66015971606034%\n",
      "epoch 29\n",
      "training\n",
      "\tTraining epoch 29 Accuracy: 97.88315770012942%\n",
      "testing\n",
      "\ttesting accuracy: 29.370008873114465%\n",
      "epoch 30\n",
      "training\n",
      "\tTraining epoch 30 Accuracy: 97.68441486411537%\n",
      "testing\n",
      "\ttesting accuracy: 26.35314995563443%\n",
      "epoch 31\n",
      "training\n",
      "\tTraining epoch 31 Accuracy: 97.72601220188575%\n",
      "testing\n",
      "\ttesting accuracy: 26.97426796805679%\n",
      "epoch 32\n",
      "training\n",
      "\tTraining epoch 32 Accuracy: 98.04492512479202%\n",
      "testing\n",
      "\ttesting accuracy: 31.588287488908605%\n",
      "epoch 33\n",
      "training\n",
      "\tTraining epoch 33 Accuracy: 98.31299685709004%\n",
      "testing\n",
      "\ttesting accuracy: 30.346051464063887%\n",
      "epoch 34\n",
      "training\n",
      "\tTraining epoch 34 Accuracy: 98.04954705121095%\n",
      "testing\n",
      "\ttesting accuracy: 23.070097604259097%\n",
      "epoch 35\n",
      "training\n",
      "\tTraining epoch 35 Accuracy: 98.32686263634683%\n",
      "testing\n",
      "\ttesting accuracy: 28.926353149955634%\n",
      "epoch 36\n",
      "training\n",
      "\tTraining epoch 36 Accuracy: 97.96173044925125%\n",
      "testing\n",
      "\ttesting accuracy: 29.19254658385093%\n",
      "epoch 37\n",
      "training\n",
      "\tTraining epoch 37 Accuracy: 98.4840081345905%\n",
      "testing\n",
      "\ttesting accuracy: 30.612244897959183%\n",
      "epoch 38\n",
      "training\n",
      "\tTraining epoch 38 Accuracy: 98.32686263634683%\n",
      "testing\n",
      "\ttesting accuracy: 27.50665483584738%\n",
      "epoch 39\n",
      "training\n",
      "\tTraining epoch 39 Accuracy: 98.44241079682011%\n",
      "testing\n",
      "\ttesting accuracy: 28.748890860692104%\n",
      "epoch 40\n",
      "training\n",
      "\tTraining epoch 40 Accuracy: 98.37308190053615%\n",
      "testing\n",
      "\ttesting accuracy: 26.53061224489796%\n",
      "epoch 41\n",
      "training\n",
      "\tTraining epoch 41 Accuracy: 98.4701423553337%\n",
      "testing\n",
      "\ttesting accuracy: 24.22360248447205%\n",
      "epoch 42\n",
      "training\n",
      "\tTraining epoch 42 Accuracy: 98.53484932519875%\n",
      "testing\n",
      "\ttesting accuracy: 26.264418811002663%\n",
      "epoch 43\n",
      "training\n",
      "\tTraining epoch 43 Accuracy: 98.67350711776669%\n",
      "testing\n",
      "\ttesting accuracy: 29.370008873114465%\n",
      "epoch 44\n",
      "training\n",
      "\tTraining epoch 44 Accuracy: 98.69661674986135%\n",
      "testing\n",
      "\ttesting accuracy: 32.03194321206744%\n",
      "epoch 45\n",
      "training\n",
      "\tTraining epoch 45 Accuracy: 98.46089850249584%\n",
      "testing\n",
      "\ttesting accuracy: 31.588287488908605%\n",
      "epoch 46\n",
      "training\n",
      "\tTraining epoch 46 Accuracy: 98.59955629506378%\n",
      "testing\n",
      "\ttesting accuracy: 28.39396628216504%\n",
      "epoch 47\n",
      "training\n",
      "\tTraining epoch 47 Accuracy: 98.719726381956%\n",
      "testing\n",
      "\ttesting accuracy: 28.482697426796804%\n",
      "epoch 48\n",
      "training\n",
      "\tTraining epoch 48 Accuracy: 98.6180440007395%\n",
      "testing\n",
      "\ttesting accuracy: 29.281277728482696%\n",
      "epoch 49\n",
      "training\n",
      "\tTraining epoch 49 Accuracy: 98.68737289702348%\n",
      "testing\n",
      "\ttesting accuracy: 28.482697426796804%\n",
      "epoch 50\n",
      "training\n",
      "\tTraining epoch 50 Accuracy: 98.61342207432058%\n",
      "testing\n",
      "\ttesting accuracy: 30.70097604259095%\n",
      "epoch 51\n",
      "training\n",
      "\tTraining epoch 51 Accuracy: 98.3961915326308%\n",
      "testing\n",
      "\ttesting accuracy: 22.448979591836736%\n",
      "epoch 52\n",
      "training\n",
      "\tTraining epoch 52 Accuracy: 98.45165464965798%\n",
      "testing\n",
      "\ttesting accuracy: 30.70097604259095%\n",
      "epoch 53\n",
      "training\n",
      "\tTraining epoch 53 Accuracy: 98.52560547236088%\n",
      "testing\n",
      "\ttesting accuracy: 21.73913043478261%\n",
      "epoch 54\n",
      "training\n",
      "\tTraining epoch 54 Accuracy: 98.35921612127935%\n",
      "testing\n",
      "\ttesting accuracy: 28.39396628216504%\n",
      "epoch 55\n",
      "training\n",
      "\tTraining epoch 55 Accuracy: 98.7335921612128%\n",
      "testing\n",
      "\ttesting accuracy: 29.81366459627329%\n",
      "epoch 56\n",
      "training\n",
      "\tTraining epoch 56 Accuracy: 98.90460343871325%\n",
      "testing\n",
      "\ttesting accuracy: 31.677018633540374%\n",
      "epoch 57\n",
      "training\n",
      "\tTraining epoch 57 Accuracy: 99.09872434830838%\n",
      "testing\n",
      "\ttesting accuracy: 28.926353149955634%\n",
      "epoch 58\n",
      "training\n",
      "\tTraining epoch 58 Accuracy: 98.83989646884821%\n",
      "testing\n",
      "\ttesting accuracy: 28.748890860692104%\n",
      "epoch 59\n",
      "training\n",
      "\tTraining epoch 59 Accuracy: 98.719726381956%\n",
      "testing\n",
      "\ttesting accuracy: 22.981366459627328%\n",
      "epoch 60\n",
      "training\n",
      "\tTraining epoch 60 Accuracy: 98.30375300425217%\n",
      "testing\n",
      "\ttesting accuracy: 31.76574977817214%\n",
      "epoch 61\n",
      "training\n",
      "\tTraining epoch 61 Accuracy: 98.81216491033463%\n",
      "testing\n",
      "\ttesting accuracy: 22.448979591836736%\n",
      "epoch 62\n",
      "training\n",
      "\tTraining epoch 62 Accuracy: 98.76594564614531%\n",
      "testing\n",
      "\ttesting accuracy: 28.482697426796804%\n",
      "epoch 63\n",
      "training\n",
      "\tTraining epoch 63 Accuracy: 98.81216491033463%\n",
      "testing\n",
      "\ttesting accuracy: 27.15173025732032%\n",
      "epoch 64\n",
      "training\n",
      "\tTraining epoch 64 Accuracy: 98.81678683675356%\n",
      "testing\n",
      "\ttesting accuracy: 34.25022182786158%\n",
      "epoch 65\n",
      "training\n",
      "\tTraining epoch 65 Accuracy: 98.96006655574043%\n",
      "testing\n",
      "\ttesting accuracy: 32.298136645962735%\n",
      "epoch 66\n",
      "training\n",
      "\tTraining epoch 66 Accuracy: 98.27602144573858%\n",
      "testing\n",
      "\ttesting accuracy: 28.216503992901508%\n",
      "epoch 67\n",
      "training\n",
      "\tTraining epoch 67 Accuracy: 98.72897023479386%\n",
      "testing\n",
      "\ttesting accuracy: 24.755989352262645%\n",
      "epoch 68\n",
      "training\n",
      "\tTraining epoch 68 Accuracy: 98.9415788500647%\n",
      "testing\n",
      "\ttesting accuracy: 27.861579414374447%\n",
      "epoch 69\n",
      "training\n",
      "\tTraining epoch 69 Accuracy: 98.83527454242929%\n",
      "testing\n",
      "\ttesting accuracy: 29.724933451641526%\n",
      "epoch 70\n",
      "training\n",
      "\tTraining epoch 70 Accuracy: 98.89998151229432%\n",
      "testing\n",
      "\ttesting accuracy: 27.595385980479147%\n",
      "epoch 71\n",
      "training\n",
      "\tTraining epoch 71 Accuracy: 98.8075429839157%\n",
      "testing\n",
      "\ttesting accuracy: 29.103815439219165%\n",
      "epoch 72\n",
      "training\n",
      "\tTraining epoch 72 Accuracy: 99.08485856905158%\n",
      "testing\n",
      "\ttesting accuracy: 28.39396628216504%\n",
      "epoch 73\n",
      "training\n",
      "\tTraining epoch 73 Accuracy: 98.67812904418561%\n",
      "testing\n",
      "\ttesting accuracy: 27.950310559006212%\n",
      "epoch 74\n",
      "training\n",
      "\tTraining epoch 74 Accuracy: 98.74283601405065%\n",
      "testing\n",
      "\ttesting accuracy: 31.14463176574978%\n",
      "epoch 75\n",
      "training\n",
      "\tTraining epoch 75 Accuracy: 98.74745794046959%\n",
      "testing\n",
      "\ttesting accuracy: 22.892635314995562%\n",
      "epoch 76\n",
      "training\n",
      "\tTraining epoch 76 Accuracy: 98.50711776668516%\n",
      "testing\n",
      "\ttesting accuracy: 25.199645075421472%\n",
      "epoch 77\n",
      "training\n",
      "\tTraining epoch 77 Accuracy: 98.50711776668516%\n",
      "testing\n",
      "\ttesting accuracy: 31.055900621118013%\n",
      "epoch 78\n",
      "training\n",
      "\tTraining epoch 78 Accuracy: 98.84451839526714%\n",
      "testing\n",
      "\ttesting accuracy: 31.854480922803905%\n",
      "epoch 79\n",
      "training\n",
      "\tTraining epoch 79 Accuracy: 98.95082270290257%\n",
      "testing\n",
      "\ttesting accuracy: 31.14463176574978%\n",
      "epoch 80\n",
      "training\n",
      "\tTraining epoch 80 Accuracy: 99.18191902384915%\n",
      "testing\n",
      "\ttesting accuracy: 28.926353149955634%\n",
      "epoch 81\n",
      "training\n",
      "\tTraining epoch 81 Accuracy: 98.8814938066186%\n",
      "testing\n",
      "\ttesting accuracy: 22.09405501330967%\n",
      "epoch 82\n",
      "training\n",
      "\tTraining epoch 82 Accuracy: 99.2188944352006%\n",
      "testing\n",
      "\ttesting accuracy: 29.0150842945874%\n",
      "epoch 83\n",
      "training\n",
      "\tTraining epoch 83 Accuracy: 98.93695692364578%\n",
      "testing\n",
      "\ttesting accuracy: 28.305235137533273%\n",
      "epoch 84\n",
      "training\n",
      "\tTraining epoch 84 Accuracy: 98.64115363283416%\n",
      "testing\n",
      "\ttesting accuracy: 29.724933451641526%\n",
      "epoch 85\n",
      "training\n",
      "\tTraining epoch 85 Accuracy: 98.85838417452395%\n",
      "testing\n",
      "\ttesting accuracy: 35.04880212954747%\n",
      "epoch 86\n",
      "training\n",
      "\tTraining epoch 86 Accuracy: 99.0293954520244%\n",
      "testing\n",
      "\ttesting accuracy: 26.88553682342502%\n",
      "epoch 87\n",
      "training\n",
      "\tTraining epoch 87 Accuracy: 98.99704196709189%\n",
      "testing\n",
      "\ttesting accuracy: 23.86867790594499%\n",
      "epoch 88\n",
      "training\n",
      "\tTraining epoch 88 Accuracy: 98.7798114254021%\n",
      "testing\n",
      "\ttesting accuracy: 23.158828748890862%\n",
      "epoch 89\n",
      "training\n",
      "\tTraining epoch 89 Accuracy: 98.63653170641524%\n",
      "testing\n",
      "\ttesting accuracy: 31.32209405501331%\n",
      "epoch 90\n",
      "training\n",
      "\tTraining epoch 90 Accuracy: 98.52098354594195%\n",
      "testing\n",
      "\ttesting accuracy: 24.489795918367346%\n",
      "epoch 91\n",
      "training\n",
      "\tTraining epoch 91 Accuracy: 98.75670179330746%\n",
      "testing\n",
      "\ttesting accuracy: 26.264418811002663%\n",
      "epoch 92\n",
      "training\n",
      "\tTraining epoch 92 Accuracy: 99.08485856905158%\n",
      "testing\n",
      "\ttesting accuracy: 32.120674356699205%\n",
      "epoch 93\n",
      "training\n",
      "\tTraining epoch 93 Accuracy: 99.14032168607876%\n",
      "testing\n",
      "\ttesting accuracy: 33.984028393966284%\n",
      "epoch 94\n",
      "training\n",
      "\tTraining epoch 94 Accuracy: 99.12183398040303%\n",
      "testing\n",
      "\ttesting accuracy: 31.588287488908605%\n",
      "epoch 95\n",
      "training\n",
      "\tTraining epoch 95 Accuracy: 99.07561471621372%\n",
      "testing\n",
      "\ttesting accuracy: 32.03194321206744%\n",
      "epoch 96\n",
      "training\n",
      "\tTraining epoch 96 Accuracy: 98.85838417452395%\n",
      "testing\n",
      "\ttesting accuracy: 22.981366459627328%\n",
      "epoch 97\n",
      "training\n",
      "\tTraining epoch 97 Accuracy: 98.8676280273618%\n",
      "testing\n",
      "\ttesting accuracy: 32.74179236912156%\n",
      "epoch 98\n",
      "training\n",
      "\tTraining epoch 98 Accuracy: 98.77518949898318%\n",
      "testing\n",
      "\ttesting accuracy: 28.039041703637977%\n",
      "epoch 99\n",
      "training\n",
      "\tTraining epoch 99 Accuracy: 99.05250508411906%\n",
      "testing\n",
      "\ttesting accuracy: 29.19254658385093%\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00001\n",
    "criterion = nn.NLLLoss()\n",
    "momentum = 0.9\n",
    "cnn = VGG16(in_dim, num_classes[0]).to(device)\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "train_batch_size = 100\n",
    "test_batch_size = 10\n",
    "\n",
    "# Create Dataset objects, then create torch dataloader\n",
    "train_dataset = SimpleDataset(x_train, y_train)\n",
    "test_dataset = SimpleDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "def train(net, loader, optimizer, epoch, device):\n",
    "    print(f'training')\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # clear up gradients for backprop\n",
    "        optimizer.zero_grad()\n",
    "        output = F.log_softmax(net(data), dim=1)\n",
    "        #print(f'output: {output} target: {target}')\n",
    "        # use NLL loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradients and make updates\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += (pred.eq(target.data.view_as(pred)).sum().item())\n",
    "\n",
    "    print(f'\\tTraining epoch {epoch} Accuracy: {100 * correct / len(loader.dataset)}%')\n",
    "\n",
    "\n",
    "def test(net, loader, device):\n",
    "    print(f'testing')\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = net(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += (pred.eq(target.data.view_as(pred)).sum().item())\n",
    "\n",
    "            total = total + 1\n",
    "    accuracy = 100 * correct / len(loader.dataset)\n",
    "    print(f'\\ttesting accuracy: {accuracy}%')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "n_epoch = 100\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print(f'epoch {epoch}')\n",
    "    train(cnn, train_loader, optimizer, epoch, device)\n",
    "    test(cnn, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
