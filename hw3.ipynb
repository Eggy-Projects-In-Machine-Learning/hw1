{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" IMPORTING DATA \"\"\"\n",
    "\n",
    "def import_data(file_name):\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(file_name, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "\n",
    "        # skip first row because it has labels\n",
    "        next(csvreader)\n",
    "        data_indices = [1,2,3,4,5,7,8,9,10]\n",
    "        class_index = 6\n",
    "\n",
    "        for row in csvreader:\n",
    "            data.append([row[i] for i in data_indices])\n",
    "            labels.append(float(row[class_index]))\n",
    "\n",
    "    # Convert the list to a numpy array\n",
    "    data_array = np.array(data)\n",
    "\n",
    "    # add bias\n",
    "    bias = np.ones((len(data_array), 1))\n",
    "    data_array = np.hstack((bias, data_array))\n",
    "\n",
    "    data_array = data_array.astype(np.float32)\n",
    "    label_array = np.zeros((len(labels), 2))\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        if label > 0.01:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        label_array[i][label] = 1\n",
    "\n",
    "    print(f'labels: {label_array}')\n",
    "    class_a_count = np.sum(label_array[:, 0])\n",
    "    class_b_count = np.sum(label_array[:, 1])\n",
    "    print(f'label array shape: {label_array.shape}')\n",
    "    # baseline accuracy is the percentage of majority class, which is accuracy score we compare to indicate the model actually learned something useful\n",
    "    print(f'label statistics: class A {class_a_count}, class B {class_b_count}, baseline accuracy: {np.maximum(class_a_count, class_b_count)/(len(data_array))}')\n",
    "    return data_array, label_array\n",
    "\n",
    "def split_data(X, Y, test_ratio):\n",
    "    num_test = int(len(X) * test_ratio)\n",
    "    test_indices = np.random.choice(len(X), num_test, replace=False)\n",
    "    Xtest = X[test_indices, :]\n",
    "    Ytest = Y[test_indices, :]\n",
    "\n",
    "    X = np.delete(X, test_indices, axis=0)\n",
    "    Y = np.delete(Y, test_indices, axis=0)\n",
    "    return X, Y, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.weights = []\n",
    "\n",
    "        # initializing weights to small random values\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.weights.append(np.random.rand(layer_sizes[i], layer_sizes[i - 1]) * 0.1)\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def d_tanh(self, x):\n",
    "        return 1 - np.power(np.tanh(x), 2)\n",
    "\n",
    "    def output_func(self, X):\n",
    "        row_maxes = X.max(axis=1).reshape(-1, 1)\n",
    "        result = (X == row_maxes).astype(int)\n",
    "        return result\n",
    "    \n",
    "    # returns the final classification result\n",
    "    def predict(self, X):\n",
    "        A_0 = X.T\n",
    "        A_1 = self.weights[0] @ A_0\n",
    "        A_1 = self.tanh(A_1)\n",
    "        A_2 = self.weights[1] @ A_1\n",
    "        A_2 = self.output_func(A_2.T)\n",
    "        return A_2\n",
    "    \n",
    "    # returns full history of forward so we can perform backpropagation\n",
    "    def forward(self, X):\n",
    "        A_0 = X\n",
    "        A_1 = self.weights[0] @ A_0\n",
    "        A_1 = self.tanh(A_1)\n",
    "        A_2 = self.weights[1] @ A_1\n",
    "        return (A_0, A_1, A_2)\n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "        A_0 = X\n",
    "        A_0 = A_0.reshape((len(A_0), 1))\n",
    "\n",
    "        # forward propagation\n",
    "        A_0, A_1, A_2 = self.forward(A_0)\n",
    "        #print(f'shape: a0: {A_0.shape} a1: {A_1.shape} a2: {A_2.shape} y: {Y.shape}')\n",
    "\n",
    "        # backward: error of output layer\n",
    "        Y = Y.reshape((len(Y), 1))\n",
    "        dA_2 = A_2 - Y\n",
    "\n",
    "        # backward: compute weight gradient of layers\n",
    "        dW_1 = dA_2 @ A_1.T\n",
    "        dA_1 = self.weights[1].T @ dA_2 * self.d_tanh(A_1)\n",
    "        dW_0 = dA_1 @ A_0.T\n",
    "\n",
    "        # final gradient\n",
    "        weight_gradients = [dW_0, dW_1]\n",
    "        return weight_gradients\n",
    "\n",
    "    \n",
    "    def train(self, X, Y, total_epoch, learning_rate=0.03, learning_rate_decay=0.8):\n",
    "        print(\"beginning training\")\n",
    "        accuracy_history = np.zeros((total_epoch + 1,))\n",
    "        for epoch in range(total_epoch):\n",
    "\n",
    "            # variable learning rate adjustment\n",
    "            # TODO: better decay algorithm, such as checking error slope\n",
    "            if epoch % (total_epoch // 10) == 0:\n",
    "                learning_rate *= learning_rate_decay\n",
    "                print(f\"epoch {epoch} with learning rate {np.around(learning_rate, 4)}\")\n",
    "\n",
    "            for i in range(0, len(X)):\n",
    "\n",
    "                weight_gradients = self.backward(X[i], Y[i])\n",
    "                # subtract the gradient from the weights\n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] -= learning_rate * weight_gradients[j]\n",
    "\n",
    "            accuracy = self.test(X, Y)\n",
    "            accuracy_history[epoch + 1] = accuracy\n",
    "            if epoch % (total_epoch // 10) == 0:\n",
    "                print(f'training accuracy: {np.around(accuracy, 5)}')\n",
    "        \n",
    "        return accuracy_history\n",
    "            \n",
    "\n",
    "    def test(self, X, Y):\n",
    "        results = self.predict(X)\n",
    "        results = self.output_func(results)\n",
    "        incorrect = np.abs(Y - results)\n",
    "\n",
    "        # find rowwise sum, and set all sum above 0 to 1\n",
    "        rowwise_sum = np.sum(incorrect, axis=1)\n",
    "        num_incorrect = np.sum((rowwise_sum > 0).astype(int))\n",
    "        accuracy = 1 - (num_incorrect/len(X))\n",
    "        return accuracy\n",
    "\n",
    "    def correct(self, x, ans):\n",
    "        return np.sign(x) == np.sign(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "label array shape: (3654, 2)\n",
      "label statistics: class A 2079.0, class B 1575.0, baseline accuracy: 0.5689655172413793\n",
      "Shapes: X: (3289, 10), Y: (3289, 2), Xtest: (365, 10), Ytest: (365, 2)\n",
      "beginning training\n",
      "epoch 0 with learning rate 0.0065\n",
      "training accuracy: 0.71511\n",
      "epoch 10 with learning rate 0.0042\n",
      "training accuracy: 0.73366\n",
      "epoch 20 with learning rate 0.0027\n",
      "training accuracy: 0.74065\n",
      "epoch 30 with learning rate 0.0018\n",
      "training accuracy: 0.74308\n",
      "epoch 40 with learning rate 0.0012\n",
      "training accuracy: 0.74795\n",
      "epoch 50 with learning rate 0.0008\n",
      "training accuracy: 0.74977\n",
      "epoch 60 with learning rate 0.0005\n",
      "training accuracy: 0.75068\n",
      "epoch 70 with learning rate 0.0003\n",
      "training accuracy: 0.74977\n",
      "epoch 80 with learning rate 0.0002\n",
      "training accuracy: 0.74856\n",
      "epoch 90 with learning rate 0.0001\n",
      "training accuracy: 0.74825\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ACCURACY: 0.7643835616438356\n"
     ]
    }
   ],
   "source": [
    "\"\"\"TESTING\"\"\"\n",
    "\n",
    "file = '../../Data/weather/weather_prediction_dataset.csv'\n",
    "X, Y = import_data(file)\n",
    "\n",
    "def custom_nn():\n",
    "    Xtrain, Ytrain, Xtest, Ytest = split_data(X, Y, 0.1)\n",
    "    print(f'Shapes: X: {Xtrain.shape}, Y: {Ytrain.shape}, Xtest: {Xtest.shape}, Ytest: {Ytest.shape}')\n",
    "    network1 = NeuralNetwork([10, 20, 2])\n",
    "    total_epoch = 100\n",
    "    error_graph = network1.train(Xtrain, Ytrain, total_epoch, 0.01, 0.65)\n",
    "\n",
    "    # plotting training accuracy\n",
    "    plt.scatter(np.linspace(0, total_epoch, len(error_graph)), error_graph, s=5)\n",
    "    plt.title(\"training accuracy history\")\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = network1.test(Xtest, Ytest)\n",
    "    print(f\"TESTING ACCURACY: {accuracy}\")\n",
    "\n",
    "custom_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, dimensions):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dimensions = dimensions\n",
    "        self.layer_list = nn.ModuleList()\n",
    "\n",
    "        for layer_num in range(len(dimensions) - 1):\n",
    "            self.layer_list.append(nn.Linear(dimensions[layer_num], dimensions[layer_num + 1]))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(-1, self.dimensions[0])\n",
    "\n",
    "        for i in range(len(self.layer_list)):\n",
    "            x = F.relu(self.layer_list[i](x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def test(net, loader, device):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = net(data)\n",
    "\n",
    "            output_np = output.cpu().detach().numpy()\n",
    "            answer = target.cpu().detach().numpy()\n",
    "            \n",
    "            output_np = output_func(output_np)\n",
    "            correct += get_num_correct(output_np, answer)\n",
    "    \n",
    "    accuracy = (correct / len(loader.dataset))\n",
    "    print(f'TEST ACCURACY: {accuracy}')\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def output_func(X):\n",
    "    row_maxes = X.max(axis=1).reshape(-1, 1)\n",
    "    result = (X == row_maxes).astype(int)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_num_correct(results, Y):\n",
    "    results = output_func(results)\n",
    "    incorrect = np.abs(Y - results)\n",
    "\n",
    "    # find rowwise sum, and set all sum above 0 to 1\n",
    "    rowwise_sum = np.sum(incorrect, axis=1)\n",
    "    num_incorrect = np.sum((rowwise_sum > 0).astype(int))\n",
    "    return len(results) - num_incorrect\n",
    "\n",
    "\n",
    "def train(net, loader, optimizer, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    net.train()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in loader:\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output_np = output.cpu().detach().numpy()\n",
    "        answer = target.cpu().detach().numpy()\n",
    "\n",
    "        # converting to 1 hot encoding\n",
    "        output_np = output_func(output_np)\n",
    "        correct += get_num_correct(output_np, answer)\n",
    "        total += len(output_np)\n",
    "\n",
    "    print(f'\\ttraining accuracy: {(correct / len(loader.dataset))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: X: (3288, 10), Y: (3288, 2), Xtest: (366, 10), Ytest: (366, 2)\n",
      "Training epoch: 0\n",
      "\ttraining accuracy: 0.704683698296837\n",
      "Training epoch: 1\n",
      "\ttraining accuracy: 0.7208029197080292\n",
      "Training epoch: 2\n",
      "\ttraining accuracy: 0.7396593673965937\n",
      "Training epoch: 3\n",
      "\ttraining accuracy: 0.7375304136253041\n",
      "Training epoch: 4\n",
      "\ttraining accuracy: 0.7347931873479319\n",
      "Training epoch: 5\n",
      "\ttraining accuracy: 0.7354014598540146\n",
      "Training epoch: 6\n",
      "\ttraining accuracy: 0.7341849148418491\n",
      "Training epoch: 7\n",
      "\ttraining accuracy: 0.7402676399026764\n",
      "Training epoch: 8\n",
      "\ttraining accuracy: 0.7329683698296837\n",
      "Training epoch: 9\n",
      "\ttraining accuracy: 0.7277980535279805\n",
      "Testing\n",
      "TEST ACCURACY: 0.73224043715847\n"
     ]
    }
   ],
   "source": [
    "def torch_nn():\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "    print(f'Shapes: X: {Xtrain.shape}, Y: {Ytrain.shape}, Xtest: {Xtest.shape}, Ytest: {Ytest.shape}')\n",
    "    \n",
    "    # hyperparameters\n",
    "    train_batch_size = 10\n",
    "    test_batch_size = 10\n",
    "    total_epoch = 10\n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    dimensions = [10, 5, 5, 2]\n",
    "\n",
    "    # PREPARING DATA\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    Xtrain = torch.tensor(Xtrain, dtype=torch.float32)\n",
    "    Ytrain = torch.tensor(Ytrain, dtype=torch.float32)\n",
    "    Xtest = torch.tensor(Xtest, dtype=torch.float32)\n",
    "    Ytest = torch.tensor(Ytest, dtype=torch.float32)\n",
    "\n",
    "    # Create Dataset objects, then create torch dataloader\n",
    "    train_dataset = SimpleDataset(Xtrain, Ytrain)\n",
    "    test_dataset = SimpleDataset(Xtest, Ytest)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    # CREATING NEURAL NETWORK OBJECT\n",
    "    network = TorchNetwork(dimensions)\n",
    "    network = network.to(device)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "\n",
    "    # TRAINING\n",
    "    for epoch in range(total_epoch):\n",
    "        print(f'Training epoch: {epoch}')\n",
    "        train(network, train_loader, optimizer, device)\n",
    "\n",
    "    # TESTING\n",
    "    print(\"Testing\")\n",
    "    test(network, test_loader, device)\n",
    "    \n",
    "\n",
    "torch_nn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
