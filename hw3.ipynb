{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this task is to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" IMPORTING DATA \"\"\"\n",
    "\n",
    "def import_data(file_name):\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(file_name, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "\n",
    "        # skip first row because it has labels\n",
    "        next(csvreader)\n",
    "        data_indices = [1,2,3,4,5,7,8,9,10]\n",
    "        class_index = 6\n",
    "\n",
    "        for row in csvreader:\n",
    "            data.append([row[i] for i in data_indices])\n",
    "            labels.append(float(row[class_index]))\n",
    "\n",
    "    # Convert the list to a numpy array\n",
    "    data_array = np.array(data)\n",
    "\n",
    "    # add bias\n",
    "    bias = np.ones((len(data_array), 1))\n",
    "    data_array = np.hstack((bias, data_array))\n",
    "\n",
    "    data_array = data_array.astype(np.float32)\n",
    "    label_array = np.zeros((len(labels), 2))\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        if label > 0.01:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        label_array[i][label] = 1\n",
    "\n",
    "    class_a_count = np.sum(label_array[:, 0])\n",
    "    class_b_count = np.sum(label_array[:, 1])\n",
    "    # baseline accuracy is the percentage of majority class, which is accuracy score we compare to indicate the model actually learned something useful\n",
    "    print(f'label statistics: class A {class_a_count}, class B {class_b_count}, baseline accuracy: {np.maximum(class_a_count, class_b_count)/(len(data_array))}')\n",
    "    return data_array, label_array\n",
    "\n",
    "def split_data(X, Y, test_ratio):\n",
    "    num_test = int(len(X) * test_ratio)\n",
    "    test_indices = np.random.choice(len(X), num_test, replace=False)\n",
    "    Xtest = X[test_indices, :]\n",
    "    Ytest = Y[test_indices, :]\n",
    "\n",
    "    X = np.delete(X, test_indices, axis=0)\n",
    "    Y = np.delete(Y, test_indices, axis=0)\n",
    "    return X, Y, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.weights = []\n",
    "\n",
    "        # initializing weights to small random values\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.weights.append(np.random.rand(layer_sizes[i], layer_sizes[i - 1]) * 0.1)\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def d_tanh(self, x):\n",
    "        return 1 - np.power(np.tanh(x), 2)\n",
    "\n",
    "    def output_func(self, X):\n",
    "        row_maxes = X.max(axis=1).reshape(-1, 1)\n",
    "        result = (X == row_maxes).astype(int)\n",
    "        return result\n",
    "    \n",
    "    # returns the final classification result\n",
    "    def predict(self, X):\n",
    "        A_0 = X.T\n",
    "        A_1 = self.weights[0] @ A_0\n",
    "        A_1 = self.tanh(A_1)\n",
    "        A_2 = self.weights[1] @ A_1\n",
    "        A_2 = self.output_func(A_2.T)\n",
    "        return A_2\n",
    "    \n",
    "    # returns full history of forward so we can perform backpropagation\n",
    "    def forward(self, X):\n",
    "        A_0 = X\n",
    "        A_1 = self.weights[0] @ A_0\n",
    "        A_1 = self.tanh(A_1)\n",
    "        A_2 = self.weights[1] @ A_1\n",
    "        return (A_0, A_1, A_2)\n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "        A_0 = X\n",
    "        A_0 = A_0.reshape((len(A_0), 1))\n",
    "\n",
    "        # forward propagation\n",
    "        A_0, A_1, A_2 = self.forward(A_0)\n",
    "        #print(f'shape: a0: {A_0.shape} a1: {A_1.shape} a2: {A_2.shape} y: {Y.shape}')\n",
    "\n",
    "        # backward: error of output layer\n",
    "        Y = Y.reshape((len(Y), 1))\n",
    "        dA_2 = A_2 - Y\n",
    "\n",
    "        # backward: compute weight gradient of layers\n",
    "        dW_1 = dA_2 @ A_1.T\n",
    "        dA_1 = self.weights[1].T @ dA_2 * self.d_tanh(A_1)\n",
    "        dW_0 = dA_1 @ A_0.T\n",
    "\n",
    "        # final gradient\n",
    "        weight_gradients = [dW_0, dW_1]\n",
    "        return weight_gradients\n",
    "\n",
    "    \n",
    "    def train(self, X, Y, total_epoch, learning_rate=0.03, learning_rate_decay=0.8):\n",
    "        print(\"beginning training\")\n",
    "        for epoch in range(total_epoch):\n",
    "\n",
    "            # variable learning rate adjustment\n",
    "            # TODO: better decay algorithm, such as checking error slope\n",
    "            if epoch % (total_epoch // 10) == 0:\n",
    "                learning_rate *= learning_rate_decay\n",
    "                print(f\"epoch {epoch} with learning rate {np.around(learning_rate, 4)}\")\n",
    "\n",
    "            for i in range(0, len(X)):\n",
    "\n",
    "                weight_gradients = self.backward(X[i], Y[i])\n",
    "                # subtract the gradient from the weights\n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] -= learning_rate * weight_gradients[j]\n",
    "\n",
    "            accuracy = self.test(X, Y)\n",
    "            if epoch % (total_epoch // 10) == 0:\n",
    "                print(f'training accuracy: {np.around(accuracy, 5)}')\n",
    "            \n",
    "\n",
    "    def test(self, X, Y):\n",
    "        results = self.predict(X)\n",
    "        results = self.output_func(results)\n",
    "        incorrect = np.abs(Y - results)\n",
    "\n",
    "        # find rowwise sum, and set all sum above 0 to 1\n",
    "        rowwise_sum = np.sum(incorrect, axis=1)\n",
    "        num_incorrect = np.sum((rowwise_sum > 0).astype(int))\n",
    "        accuracy = 1 - (num_incorrect/len(X))\n",
    "        return accuracy\n",
    "\n",
    "    def correct(self, x, ans):\n",
    "        return np.sign(x) == np.sign(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label statistics: class A 2079.0, class B 1575.0, baseline accuracy: 0.5689655172413793\n",
      "Shapes: X: (3289, 10), Y: (3289, 2), Xtest: (365, 10), Ytest: (365, 2)\n",
      "beginning training\n",
      "epoch 0 with learning rate 0.0065\n",
      "training accuracy: 0.72423\n",
      "epoch 10 with learning rate 0.0042\n",
      "training accuracy: 0.73761\n",
      "epoch 20 with learning rate 0.0027\n",
      "training accuracy: 0.74156\n",
      "epoch 30 with learning rate 0.0018\n",
      "training accuracy: 0.74673\n",
      "epoch 40 with learning rate 0.0012\n",
      "training accuracy: 0.74947\n",
      "epoch 50 with learning rate 0.0008\n",
      "training accuracy: 0.75251\n",
      "epoch 60 with learning rate 0.0005\n",
      "training accuracy: 0.75403\n",
      "epoch 70 with learning rate 0.0003\n",
      "training accuracy: 0.75403\n",
      "epoch 80 with learning rate 0.0002\n",
      "training accuracy: 0.75312\n",
      "epoch 90 with learning rate 0.0001\n",
      "training accuracy: 0.75129\n",
      "TESTING ACCURACY: 0.7397260273972603\n"
     ]
    }
   ],
   "source": [
    "\"\"\"TESTING\"\"\"\n",
    "\n",
    "file = '../../Data/weather/weather_prediction_dataset.csv'\n",
    "X, Y = import_data(file)\n",
    "\n",
    "def custom_nn():\n",
    "    Xtrain, Ytrain, Xtest, Ytest = split_data(X, Y, 0.1)\n",
    "    print(f'Shapes: X: {Xtrain.shape}, Y: {Ytrain.shape}, Xtest: {Xtest.shape}, Ytest: {Ytest.shape}')\n",
    "    network1 = NeuralNetwork([10, 20, 2])\n",
    "    total_epoch = 100\n",
    "    network1.train(Xtrain, Ytrain, total_epoch, 0.01, 0.65)\n",
    "\n",
    "    accuracy = network1.test(Xtest, Ytest)\n",
    "    print(f\"TESTING ACCURACY: {accuracy}\")\n",
    "\n",
    "custom_nn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I will be implementing the same classification task but with PyTorch. I will be using a fully connected neural network with 2 hidden layers. This is done by creating an object that inherents the nn.Module object and defining a forward function. My implementation allows the neural network to be initialized with an array specifing the dimensions of each layer, with index 0 being the input and last index the output.\n",
    "\n",
    "The following resources were used to help me write this code:\n",
    "https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html (functions to call for initializing network, backpropagation, updating the weights and for inferencing)\n",
    "https://medium.com/analytics-vidhya/creating-a-custom-dataset-and-dataloader-in-pytorch-76f210a1df5d (creating dataset and dataloader objects to load my dataset)\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html (using the cross entropy loss for classification)\n",
    "\n",
    "Additionally, the train_test_split function from sklearn is used to split the data between testing and training randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, dimensions):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dimensions = dimensions\n",
    "        self.layer_list = nn.ModuleList()\n",
    "        for layer_num in range(len(dimensions) - 1):\n",
    "            self.layer_list.append(nn.Linear(dimensions[layer_num], dimensions[layer_num + 1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.dimensions[0])\n",
    "        for i in range(len(self.layer_list)):\n",
    "            x = F.relu(self.layer_list[i](x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, loader, device):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = net(data)\n",
    "\n",
    "            output_np = output.cpu().detach().numpy()\n",
    "            answer = target.cpu().detach().numpy()\n",
    "            \n",
    "            output_np = output_func(output_np)\n",
    "            correct += get_num_correct(output_np, answer)\n",
    "    \n",
    "    accuracy = (correct / len(loader.dataset))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def output_func(X):\n",
    "    row_maxes = X.max(axis=1).reshape(-1, 1)\n",
    "    result = (X == row_maxes).astype(int)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_num_correct(results, Y):\n",
    "    # incorrect is when 1 hot encoding is wrong, computed by subtracting correct encoding and computed encoding and seeing if there exists non-zero numbers\n",
    "    results = output_func(results)\n",
    "    incorrect = np.abs(Y - results)\n",
    "\n",
    "    # find rowwise sum, and set all sum above 0 to 1\n",
    "    rowwise_sum = np.sum(incorrect, axis=1)\n",
    "    num_incorrect = np.sum((rowwise_sum > 0).astype(int))\n",
    "    return len(results) - num_incorrect\n",
    "\n",
    "\n",
    "def train(net, loader, optimizer, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    net.train()\n",
    "\n",
    "    for data, target in loader:\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    accuracy = test(net, loader, device)\n",
    "    print(f'\\ttraining accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: Xtrain: (3288, 10), Ytrain: (3288, 2), Xtest: (366, 10), Ytest: (366, 2)\n",
      "Training epoch: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttraining accuracy: 0.7314476885644768\n",
      "Training epoch: 1\n",
      "\ttraining accuracy: 0.7204987834549879\n",
      "Training epoch: 2\n",
      "\ttraining accuracy: 0.7417883211678832\n",
      "Training epoch: 3\n",
      "\ttraining accuracy: 0.7393552311435523\n",
      "Training epoch: 4\n",
      "\ttraining accuracy: 0.7439172749391727\n",
      "Training epoch: 5\n",
      "\ttraining accuracy: 0.7387469586374696\n",
      "Training epoch: 6\n",
      "\ttraining accuracy: 0.7375304136253041\n",
      "Training epoch: 7\n",
      "\ttraining accuracy: 0.7326642335766423\n",
      "Training epoch: 8\n",
      "\ttraining accuracy: 0.7025547445255474\n",
      "Training epoch: 9\n",
      "\ttraining accuracy: 0.7460462287104623\n",
      "Testing\n",
      "TEST ACCURACY: 0.73224043715847\n"
     ]
    }
   ],
   "source": [
    "def torch_nn():\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "    print(f'Shapes: Xtrain: {Xtrain.shape}, Ytrain: {Ytrain.shape}, Xtest: {Xtest.shape}, Ytest: {Ytest.shape}')\n",
    "    \n",
    "    # hyperparameters\n",
    "    dimensions = [10, 5, 5, 2]\n",
    "    train_batch_size = 10\n",
    "    test_batch_size = 10\n",
    "    total_epoch = 10\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    # PREPARING DATA\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    Xtrain = torch.tensor(Xtrain, dtype=torch.float32)\n",
    "    Ytrain = torch.tensor(Ytrain, dtype=torch.float32)\n",
    "    Xtest = torch.tensor(Xtest, dtype=torch.float32)\n",
    "    Ytest = torch.tensor(Ytest, dtype=torch.float32)\n",
    "\n",
    "    # Create Dataset objects, then create torch dataloader\n",
    "    train_dataset = SimpleDataset(Xtrain, Ytrain)\n",
    "    test_dataset = SimpleDataset(Xtest, Ytest)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    # CREATING NEURAL NETWORK OBJECT\n",
    "    network = TorchNetwork(dimensions)\n",
    "    network = network.to(device)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "\n",
    "    # TRAINING\n",
    "    for epoch in range(total_epoch):\n",
    "        print(f'Training epoch: {epoch}')\n",
    "        train(network, train_loader, optimizer, device)\n",
    "\n",
    "    # TESTING\n",
    "    print(\"Testing\")\n",
    "    accuracy = test(network, test_loader, device)\n",
    "    print(f'TEST ACCURACY: {accuracy}')\n",
    "    \n",
    "\n",
    "torch_nn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
