{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" IMPORTING DATA \"\"\"\n",
    "\n",
    "def import_data(file_name):\n",
    "    data = []\n",
    "    label = []\n",
    "    with open(file_name, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "\n",
    "        # skip first row because it has labels\n",
    "        next(csvreader)\n",
    "        data_indices = [1,2,3,4,5,7,8,9,10]\n",
    "        class_index = 6\n",
    "\n",
    "        for row in csvreader:\n",
    "            data.append([row[i] for i in data_indices])\n",
    "            label.append(row[class_index])\n",
    "\n",
    "    # Convert the list to a numpy array\n",
    "    data_array = np.array(data)\n",
    "\n",
    "    # add bias\n",
    "    bias = np.ones((len(data_array), 1))\n",
    "    data_array = np.hstack((bias, data_array))\n",
    "\n",
    "    data_array = data_array.astype(np.float32)\n",
    "    label_array = np.array(label)\n",
    "    label_array = label_array.astype(np.float32)\n",
    "    print(f'label shape: {label_array.shape}')\n",
    "\n",
    "    # here, we're setting the label to be 1 if a positive quantity is in label, otherwise it's -1\n",
    "    label_array = np.where(label_array > 0.01, 1, -1)\n",
    "    label_array = np.reshape(label_array, (len(label_array), 1))\n",
    "\n",
    "    class_a_count = np.sum(label_array == -1)\n",
    "    class_b_count = np.sum(label_array == 1)\n",
    "    # baseline accuracy is the percentage of majority class, which is accuracy score we compare to indicate the model actually learned something useful\n",
    "    print(f'label statistics: class A {class_a_count}, class B {class_b_count}, baseline accuracy: {np.maximum(class_a_count, class_b_count)/(len(data_array))}')\n",
    "    return data_array, label_array\n",
    "\n",
    "def split_data(X, Y, test_ratio):\n",
    "    num_test = int(len(X) * test_ratio)\n",
    "    test_indices = np.random.choice(len(X), num_test, replace=False)\n",
    "    Xtest = X[test_indices, :]\n",
    "    Ytest = Y[test_indices, :]\n",
    "\n",
    "    X = np.delete(X, test_indices, axis=0)\n",
    "    Y = np.delete(Y, test_indices, axis=0)\n",
    "    return X, Y, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.weights = []\n",
    "\n",
    "        # initializing weights to small random values\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.weights.append(np.random.rand(layer_sizes[i], layer_sizes[i - 1]) * 0.1)\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def d_tanh(self, x):\n",
    "        return 1 - np.power(np.tanh(x), 2)\n",
    "\n",
    "    def output_func(self, X):\n",
    "        return np.sign(X)\n",
    "    \n",
    "    # returns the final classification result\n",
    "    def predict(self, X):\n",
    "        A_0 = X.T\n",
    "        A_1 = self.weights[0] @ A_0\n",
    "        A_1 = self.tanh(A_1)\n",
    "        A_2 = self.weights[1] @ A_1\n",
    "        A_2 = self.output_func(A_2.T)\n",
    "        return A_2\n",
    "    \n",
    "    # returns full history of forward so we can perform backpropagation\n",
    "    def forward(self, X):\n",
    "        A_0 = X\n",
    "        A_1 = self.weights[0] @ A_0\n",
    "        A_1 = self.tanh(A_1)\n",
    "        A_2 = self.weights[1] @ A_1\n",
    "        return (A_0, A_1, A_2)\n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "        A_0 = X\n",
    "        A_0 = A_0.reshape((len(A_0), 1))\n",
    "\n",
    "        # forward propagation\n",
    "        A_0, A_1, A_2 = self.forward(A_0)\n",
    "\n",
    "        # backward: error of output layer\n",
    "        dA_2 = A_2 - Y\n",
    "\n",
    "        # backward: compute weight gradient of layers\n",
    "        dW_1 = dA_2 @ A_1.T\n",
    "        dA_1 = self.weights[1].T @ dA_2 * self.d_tanh(A_1)\n",
    "        dW_0 = dA_1 @ A_0.T\n",
    "\n",
    "        # final gradient\n",
    "        weight_gradients = [dW_0, dW_1]\n",
    "        return weight_gradients\n",
    "\n",
    "    \n",
    "    def train(self, X, Y, total_epoch, learning_rate=0.03, learning_rate_decay=0.8):\n",
    "        print(\"beginning training\")\n",
    "        accuracy_history = np.zeros((total_epoch + 1,))\n",
    "        for epoch in range(total_epoch):\n",
    "\n",
    "            # variable learning rate adjustment\n",
    "            # TODO: better decay algorithm, such as checking error slope\n",
    "            if epoch % (total_epoch // 10) == 0:\n",
    "                learning_rate *= learning_rate_decay\n",
    "                print(f\"epoch {epoch} with learning rate {np.around(learning_rate, 4)}\")\n",
    "\n",
    "            for i in range(0, len(X)):\n",
    "\n",
    "                weight_gradients = self.backward(X[i], Y[i])\n",
    "                # subtract the gradient from the weights\n",
    "                for j in range(len(self.weights)):\n",
    "                    self.weights[j] -= learning_rate * weight_gradients[j]\n",
    "\n",
    "            accuracy = self.test(X, Y)\n",
    "            accuracy_history[epoch + 1] = accuracy\n",
    "            if epoch % (total_epoch // 10) == 0:\n",
    "                print(f'training accuracy: {np.around(accuracy, 5)}')\n",
    "        \n",
    "        return accuracy_history\n",
    "            \n",
    "\n",
    "    def test(self, X, Y):\n",
    "        results = self.predict(X)\n",
    "        num_incorrect = np.sum(np.abs(0.5 * (Y - results)))\n",
    "        accuracy = 1 - (num_incorrect/len(X))\n",
    "        return accuracy\n",
    "\n",
    "    def correct(self, x, ans):\n",
    "        return np.sign(x) == np.sign(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label shape: (3654,)\n",
      "label statistics: class A 2079, class B 1575, baseline accuracy: 0.5689655172413793\n",
      "Shapes: X: (3289, 10), Y: (3289, 1), Xtest: (365, 10), Ytest: (365, 1)\n",
      "beginning training\n",
      "epoch 0 with learning rate 0.0065\n",
      "training accuracy: 0.72089\n",
      "epoch 10 with learning rate 0.0042\n",
      "training accuracy: 0.74217\n",
      "epoch 20 with learning rate 0.0027\n",
      "training accuracy: 0.7443\n",
      "epoch 30 with learning rate 0.0018\n",
      "training accuracy: 0.7446\n",
      "epoch 40 with learning rate 0.0012\n",
      "training accuracy: 0.74977\n",
      "epoch 50 with learning rate 0.0008\n",
      "training accuracy: 0.74977\n",
      "epoch 60 with learning rate 0.0005\n",
      "training accuracy: 0.75068\n",
      "epoch 70 with learning rate 0.0003\n",
      "training accuracy: 0.7516\n",
      "epoch 80 with learning rate 0.0002\n",
      "training accuracy: 0.75464\n",
      "epoch 90 with learning rate 0.0001\n",
      "training accuracy: 0.75403\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ACCURACY: 0.7424657534246575\n"
     ]
    }
   ],
   "source": [
    "\"\"\"TESTING\"\"\"\n",
    "\n",
    "file = '../../Data/weather/weather_prediction_dataset.csv'\n",
    "X, Y = import_data(file)\n",
    "\n",
    "def custom_nn():\n",
    "    Xtrain, Ytrain, Xtest, Ytest = split_data(X, Y, 0.1)\n",
    "    print(f'Shapes: X: {Xtrain.shape}, Y: {Ytrain.shape}, Xtest: {Xtest.shape}, Ytest: {Ytest.shape}')\n",
    "    network1 = NeuralNetwork([10, 20, 1])\n",
    "    total_epoch = 100\n",
    "    error_graph = network1.train(Xtrain, Ytrain, total_epoch, 0.01, 0.65)\n",
    "\n",
    "    # plotting training accuracy\n",
    "    plt.scatter(np.linspace(0, total_epoch, len(error_graph)), error_graph, s=5)\n",
    "    plt.title(\"training accuracy history\")\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = network1.test(Xtest, Ytest)\n",
    "    print(f\"TESTING ACCURACY: {accuracy}\")\n",
    "\n",
    "custom_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, num_hidden_layers, layer_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.layer_size = layer_size\n",
    "\n",
    "        self.layer_list = nn.ModuleList()\n",
    "\n",
    "        self.layer_list.append(nn.Linear(self.in_dim, self.layer_size))\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        for i in range(1, self.num_hidden_layers):\n",
    "            self.layer_list.append(nn.Linear(self.layer_size, self.layer_size))\n",
    "\n",
    "        self.layer_list.append(nn.Linear(self.layer_size, self.out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(-1, self.in_dim)\n",
    "\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            x = F.relu(self.layer_list[i](x))\n",
    "\n",
    "        return self.layer_list[self.num_hidden_layers](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def test(net, loader, device):\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    incorrect = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = net(data)\n",
    "\n",
    "            pred = output.cpu().detach().numpy()\n",
    "            pred = np.sign(pred)\n",
    "\n",
    "            total = total + 1\n",
    "\n",
    "            answer = target.cpu().detach().numpy()\n",
    "            incorrect += 0.5 * np.sum(np.abs(pred - answer))\n",
    "    \n",
    "    accuracy = 1 - (incorrect / len(loader.dataset))\n",
    "    print(f'Test loss: {test_loss}, accuracy: {accuracy}')\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train(net, loader, optimizer, device, log_interval=100):\n",
    "    # prepare model for training (only important for dropout, batch norm, etc.)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "    net.train()\n",
    "    incorrect = 0\n",
    "    total = 0\n",
    "    for batch_num, (data, target) in enumerate(loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = outputs.cpu().detach().numpy()\n",
    "        pred = np.sign(pred)\n",
    "\n",
    "        #print(f'output: {outputs}')\n",
    "        # TODO: USE OUTPUTS DIRECTLY RATHER THAN PRED\n",
    "        \n",
    "        #pred = outputs.data.max(1, keepdim=True)[1]\n",
    "        answer = target.cpu().detach().numpy()\n",
    "        incorrect += 0.5 * np.sum(np.abs(pred - answer))\n",
    "        total += len(outputs)\n",
    "\n",
    "        if batch_num % log_interval == 0:\n",
    "            print(f'\\taccuracy: {1 - (incorrect / total)}')\n",
    "\n",
    "    print(f'\\tfinal training accuracy: {1 - (incorrect / len(loader.dataset))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: X: (3288, 10), Y: (3288, 1), Xtest: (366, 10), Ytest: (366, 1)\n",
      "Training epoch: 0\n",
      "\taccuracy: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taccuracy: 0.5584158415841585\n",
      "\taccuracy: 0.5527363184079602\n",
      "\taccuracy: 0.5441860465116279\n",
      "\tfinal training accuracy: 0.5395377128953771\n",
      "Training epoch: 1\n",
      "\taccuracy: 0.4\n",
      "\taccuracy: 0.5495049504950495\n",
      "\taccuracy: 0.5492537313432836\n",
      "\taccuracy: 0.5438538205980066\n",
      "\tfinal training accuracy: 0.5395377128953771\n",
      "Training epoch: 2\n",
      "\taccuracy: 0.8\n",
      "\taccuracy: 0.5346534653465347\n",
      "\taccuracy: 0.5432835820895523\n",
      "\taccuracy: 0.5435215946843854\n",
      "\tfinal training accuracy: 0.5395377128953771\n",
      "Training epoch: 3\n",
      "\taccuracy: 0.8\n",
      "\taccuracy: 0.5564356435643565\n",
      "\taccuracy: 0.5477611940298508\n",
      "\taccuracy: 0.5345514950166113\n",
      "\tfinal training accuracy: 0.5395377128953771\n",
      "Training epoch: 4\n",
      "\taccuracy: 0.6\n",
      "\taccuracy: 0.5316831683168317\n",
      "\taccuracy: 0.535820895522388\n",
      "\taccuracy: 0.5395348837209302\n",
      "\tfinal training accuracy: 0.5395377128953771\n",
      "Training epoch: 5\n",
      "\taccuracy: 0.30000000000000004\n",
      "\taccuracy: 0.5475247524752476\n",
      "\taccuracy: 0.5422885572139303\n",
      "\taccuracy: 0.5421926910299003\n",
      "\tfinal training accuracy: 0.5395377128953771\n",
      "Training epoch: 6\n",
      "\taccuracy: 0.5\n",
      "\taccuracy: 0.5653465346534654\n",
      "\taccuracy: 0.5462686567164179\n",
      "\taccuracy: 0.5388704318936877\n",
      "\tfinal training accuracy: 0.5395377128953771\n",
      "Training epoch: 7\n",
      "\taccuracy: 0.5\n",
      "\taccuracy: 0.5485148514851486\n",
      "\taccuracy: 0.536318407960199\n",
      "\taccuracy: 0.539202657807309\n",
      "\tfinal training accuracy: 0.5395377128953771\n",
      "Training epoch: 8\n",
      "\taccuracy: 0.5\n",
      "\taccuracy: 0.5386138613861386\n",
      "\taccuracy: 0.5338308457711443\n",
      "\taccuracy: 0.5362126245847176\n",
      "\tfinal training accuracy: 0.5395377128953771\n",
      "Training epoch: 9\n",
      "\taccuracy: 0.6\n",
      "\taccuracy: 0.5534653465346535\n",
      "\taccuracy: 0.5472636815920398\n",
      "\taccuracy: 0.5388704318936877\n",
      "\tfinal training accuracy: 0.5395377128953771\n",
      "Testing\n",
      "Test loss: 0, accuracy: 0.5546448087431695\n"
     ]
    }
   ],
   "source": [
    "def torch_nn():\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "    print(f'Shapes: X: {Xtrain.shape}, Y: {Ytrain.shape}, Xtest: {Xtest.shape}, Ytest: {Ytest.shape}')\n",
    "    \n",
    "    # hyperparameters\n",
    "    train_batch_size = 10\n",
    "    test_batch_size = 10\n",
    "    total_epoch = 10\n",
    "    learning_rate = 0.1\n",
    "    \n",
    "    input_dim = 10\n",
    "    out_dim = 1\n",
    "    num_hidden_layers = 3\n",
    "    layer_size = 30\n",
    "\n",
    "    # PREPARING DATA\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    Xtrain = torch.tensor(Xtrain, dtype=torch.float32)\n",
    "    Ytrain = torch.tensor(Ytrain, dtype=torch.float32)\n",
    "    Xtest = torch.tensor(Xtest, dtype=torch.float32)\n",
    "    Ytest = torch.tensor(Ytest, dtype=torch.float32)\n",
    "\n",
    "    # Create Dataset objects, then create torch dataloader\n",
    "    train_dataset = SimpleDataset(Xtrain, Ytrain)\n",
    "    test_dataset = SimpleDataset(Xtest, Ytest)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    # CREATING NEURAL NETWORK OBJECT\n",
    "    network = FC(in_dim=input_dim, out_dim=out_dim, num_hidden_layers=num_hidden_layers, layer_size=layer_size)\n",
    "    network = network.to(device)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "\n",
    "    # TRAINING\n",
    "    for epoch in range(total_epoch):\n",
    "        print(f'Training epoch: {epoch}')\n",
    "        train(network, train_loader, optimizer, device)\n",
    "\n",
    "    # TESTING\n",
    "    print(\"Testing\")\n",
    "    test(network, test_loader, device)\n",
    "    \n",
    "\n",
    "torch_nn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
